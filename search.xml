<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Data-Free Knowledge Distillation for Heterogeneous Federated Learning</title>
      <link href="/2022/11/20/pmlr21-data-free-knowledge-distillation-for-pmlr21-heterogeneous-federated-learning/"/>
      <url>/2022/11/20/pmlr21-data-free-knowledge-distillation-for-pmlr21-heterogeneous-federated-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="PMLR21-Data-Free-Knowledge-Distillation-for-Heterogeneous-Federated-Learning"><a href="#PMLR21-Data-Free-Knowledge-Distillation-for-Heterogeneous-Federated-Learning" class="headerlink" title="PMLR21-Data-Free-Knowledge-Distillation-for-Heterogeneous-Federated-Learning"></a>PMLR21-Data-Free-Knowledge-Distillation-for-Heterogeneous-Federated-Learning</h1>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
          <category> About FL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About FL </tag>
            
            <tag> About Knowledge Distillation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FL</title>
      <link href="/2022/11/12/fl/"/>
      <url>/2022/11/12/fl/</url>
      
        <content type="html"><![CDATA[<h1 id="FL"><a href="#FL" class="headerlink" title="FL"></a>FL</h1><h2 id="Statistical-heterogeneity"><a href="#Statistical-heterogeneity" class="headerlink" title="Statistical heterogeneity"></a>Statistical heterogeneity</h2><h3 id="Adapt-the-global-model-to-accommodate-personalized-local-models-for-non-IID-data"><a href="#Adapt-the-global-model-to-accommodate-personalized-local-models-for-non-IID-data" class="headerlink" title="Adapt the global model to accommodate personalized local models for non-IID data"></a>Adapt the global model to accommodate personalized local models for non-IID data</h3><h4 id="Meta-learning"><a href="#Meta-learning" class="headerlink" title="Meta learning"></a>Meta learning</h4><ul><li><p><strong>arXiv’19</strong>-Improving federated learning personalization via model agnostic meta learning-(Yihan Jiang-uw, Jakub Konečný-Google research, Keith Rush, Sreeram Kannan-uw)</p></li><li><p><strong>NIPS’19</strong>-Adaptive gradient-based metalearning methods-(Mikhail Khodak-CMU, Maria-Florina Balcan-CMU, Ameet Talwalkar-CMU)</p></li><li><p><strong>NIPS’20</strong>-Personalized federated learning with theoretical guarantees: A modelagnostic meta-learning approach</p></li><li><p><strong>ICLR’20</strong>-Differentially private metalearning</p></li></ul><h4 id="Multi-task-learning"><a href="#Multi-task-learning" class="headerlink" title="Multi-task learning"></a>Multi-task learning</h4><ul><li><p><strong>NIPS’17</strong>-MOCHA: Federated multi-task learning-(Virginia Smith-stanford, Chao-Kai Chiang-usc, Maziar Sanjabi-usc, Ameet S. Talwalkar-CMU)</p></li><li><p><strong>arXiv’19</strong>-Variational federated multi-task learning</p></li><li><p><strong>ICML’19</strong>-Semi-cyclic stochastic gradient descent</p></li><li><p><strong>NIPS’19</strong>-Adaptive gradient-based metalearning methods</p></li></ul><h4 id="Transfer-learning"><a href="#Transfer-learning" class="headerlink" title="Transfer learning"></a>Transfer learning</h4><ul><li><p><strong>arXiv’19</strong>-Federated evaluation of on-device personalization-(Kangkang Wang-Google, Rajiv Mathews-Google, Chloé Kiddon-Google, Hubert Eichner-Google, Françoise Beaufays-Google, Daniel Ramage-Google)</p></li><li><p><strong>arXiv’20</strong>-Three approaches for personalization with applications to federated learning-(Yishay Mansour-Google, Mehryar Mohri-Google, Jae Ro-Google, Ananda Theertha Suresh-Google)</p></li></ul><h4 id="Knowledge-distillation"><a href="#Knowledge-distillation" class="headerlink" title="Knowledge distillation"></a>Knowledge distillation</h4><ul><li><input disabled type="checkbox"> <strong>arXiv’19</strong>-Fedmd: Heterogenous federated learning via model distillation-(Daliang Li, Junpu Wang Harvard-Yale-Pennsylvania)</li></ul><h4 id="Lottery-ticket-hypothesis"><a href="#Lottery-ticket-hypothesis" class="headerlink" title="Lottery ticket hypothesis"></a>Lottery ticket hypothesis</h4><ul><li><input disabled type="checkbox"> <strong>arXiv’20</strong>-Lotteryfl: Personalized and communication-efficient federated learning with lottery ticket hypothesis on non-iid datasets-(Ang Li-Duke, Jingwei Sun-Duke, Binghui Wang-Duke, Lin Duan-Duke, Sicheng Li-Alibaba, Yiran Chen-Duke, Hai Li-Duke)</li></ul><h3 id="Client-clustering"><a href="#Client-clustering" class="headerlink" title="Client clustering"></a>Client clustering</h3><ul><li><input disabled type="checkbox"> <strong>NIPS’20</strong>-An efficient framework for clustered federated learning-()-()-Client clustering.</li></ul><h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h3><ul><li><input disabled type="checkbox"> <strong>NIPS’19Workshop</strong>-Federated learning with local and global representations-(Paul Liang-CMU, Terrance Liu-CMU)</li><li><input disabled type="checkbox"> <strong>arXiv’21</strong>-Fed-ensemble: Improving generalization through model ensembling in federated learning</li><li><input disabled type="checkbox"> <strong>ICML’20</strong>-SCAFFOLD: Stochastic controlled averaging for federated learning</li></ul><h2 id="System-heterogeneity"><a href="#System-heterogeneity" class="headerlink" title="System heterogeneity"></a>System heterogeneity</h2><h3 id="Asynchronous-communication"><a href="#Asynchronous-communication" class="headerlink" title="Asynchronous communication"></a>Asynchronous communication</h3><h3 id="Active-sampling-of-clients"><a href="#Active-sampling-of-clients" class="headerlink" title="Active sampling of clients"></a>Active sampling of clients</h3><ul><li><input checked disabled type="checkbox"> <strong>SysML’19</strong>-Towards federated learning at scale: System design-(Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečný, Stefano Mazzocchi, H. Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage, Jason Roselander)</li><li><input disabled type="checkbox"> <strong>ICC’19</strong>-Client selection for federated learning with heterogeneous resources in mobile edge-(Takayuki Nishio-Kyoto, Ryo Yonetani-Kyoto)</li><li><input disabled type="checkbox"> <strong>OSDI’21</strong>-Oort: Efficient federated learning via guided participant selection</li><li><input disabled type="checkbox"> <strong>NSDI’20</strong>-Sol: A federated execution engine for fast distributed computation over slow networks</li></ul><h2 id="Communication"><a href="#Communication" class="headerlink" title="Communication"></a>Communication</h2><h3 id="Data-compression-techniques"><a href="#Data-compression-techniques" class="headerlink" title="Data compression techniques"></a>Data compression techniques</h3><h4 id="Quantization-and-sketching"><a href="#Quantization-and-sketching" class="headerlink" title="Quantization and sketching"></a>Quantization and sketching</h4><ul><li><input disabled type="checkbox"> <strong>arXiv’16</strong>-Federated learning: Strategies for improving communication efficiency-(Jakub Konečný-Google, H. Brendan McMahan-Google, Felix X. Yu-Google, Peter Richtárik-KAUST, Ananda Theertha Suresh-Google, Dave Bacon-Google)</li><li><input disabled type="checkbox"> <strong>NIPS’17</strong>-Qsgd: Communication-efficient sgd via gradient quantization and encoding-(Dan Alistarh-ETH, Demjan Grubic-Eth&amp;Google, Jerry Z. Li-MIT, Ryota Tomioka-Microsoft Research, Milan Vojnovic-London School of Economics)</li><li><input disabled type="checkbox"> <strong>NIPS’19</strong>-Communication efficient distributed sgd with sketching-(Nikita Ivkin-Amzaon, Daniel Rothchild-UCB, Enayat UIIah-JHU, Vladimir Braverman-JHU, Ion Stoica-UCB, Raman Arora-JHU)</li><li><input disabled type="checkbox"> <strong>arXiv’19</strong>-Error feedback fixes signsgd and other gradient compression schemes</li><li><input disabled type="checkbox"> <strong>arXiv’16</strong>-Federated learning: Strategies for improving communication efficiency</li><li><input disabled type="checkbox"> <strong>arXiv’18</strong>-Expanding the reach of federated learning by reducing client resource requirements</li><li><input disabled type="checkbox"> <strong>NIPS’18</strong>-ATOMO: Communication-efficient learning via atomic sparsification</li><li><input disabled type="checkbox"> <strong>PISIT’18</strong>-Gradient coding using the stochastic block model</li></ul><h3 id="Local-training"><a href="#Local-training" class="headerlink" title="Local training"></a>Local training</h3><ul><li><p><strong>ICAIS’17</strong>-Communication-efficient learning of deep networks from decentralized data</p></li><li><p><strong>ICLR’19</strong>-Local SGD converges fast and communicates little</p></li><li><p><input disabled type="checkbox">  CoCoA: A general framework for communication-efficient distributed optimization</p></li><li><p><strong>NSDI’20</strong>-Sol: A federated execution engine for fast distributed computation over slow networks</p></li></ul><h3 id="Split-learning"><a href="#Split-learning" class="headerlink" title="Split learning"></a>Split learning</h3><ul><li><input disabled type="checkbox"> <strong>arXiv’20</strong>-Splitfed: When federated learning meets split learning-(Chandra Thapa-Lehigh University, M.A.P. Chamikara-Lehigh University, Seyit Camtepe-Lehigh University, Lichao Sun-Lehigh University)</li></ul><h3 id="Decentralized-training"><a href="#Decentralized-training" class="headerlink" title="Decentralized training"></a>Decentralized training</h3><ul><li><input disabled type="checkbox"> <strong>ICLR’19</strong>-Anytime Minibatch: Exploiting stragglers in online distributed optimization</li><li><input disabled type="checkbox"> <strong>NIPS’19</strong>-Robust and communication-efficient collaborative learning</li></ul><h3 id="Asynchronous-and-synchronous"><a href="#Asynchronous-and-synchronous" class="headerlink" title="Asynchronous and synchronous"></a>Asynchronous and synchronous</h3><ul><li><input disabled type="checkbox"> <strong>NIPS’15</strong>-Deep learning with elastic averaging SGD</li><li><input disabled type="checkbox"> <strong>NIPS’11</strong>:HOGWILD!: A lock-free approach to parallelizing stochastic gradient descent</li></ul><h2 id="Data-privacy"><a href="#Data-privacy" class="headerlink" title="Data privacy"></a>Data privacy</h2><h3 id="Break-privacy"><a href="#Break-privacy" class="headerlink" title="Break privacy"></a>Break privacy</h3><ul><li><input disabled type="checkbox"> <strong>NIPS’20</strong>-Inverting gradients - how easy is it to break privacy in federated learning</li><li><input disabled type="checkbox"> <strong>NIPS’20</strong>-Attack of the tails: Yes, you really can backdoor federated learning</li><li><input disabled type="checkbox"> <strong>arXiv’19</strong>-Can you really backdoor federated learning?</li></ul><h3 id="Differentially-private"><a href="#Differentially-private" class="headerlink" title="Differentially private"></a>Differentially private</h3><ul><li><p><strong>PCCCS’17</strong>-Practical secure aggregation for privacy-preserving machine learning</p></li><li><p><strong>NIPS’17</strong>-Differentially private federated learning: A client level perspective</p></li><li><p><strong>ICLR’18</strong>-Learning differentially private recurrent language models</p></li><li><p><strong>MobiCom’20</strong>-Billion-Scale Federated Learning on Mobile Clients: A Submodel Design with Tunable Privacy</p></li></ul><h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><ul><li><p><strong>NIPS’17</strong>-“Can decentralized algorithms outperform centralized algorithms? A case study for decentralized parallel stochastic gradient descent</p></li><li><p><strong>arXiv’18</strong>-Communication-efficient distributed strongly convex stochastic optimization: Non-asymptotic rates</p></li><li><p><strong>SP’19</strong>-Exploiting unintended feature leakage in collaborative learning</p></li><li><p><strong>NIPS’19</strong>-Deep leakage from gradients</p></li><li><p><strong>arXiv’20</strong>-idlg: Improved deep leakage from gradients</p></li><li><p><strong>arXiv’20</strong>-Threats to federated learning: A survey</p></li><li><p><strong>arXiv’21</strong>-Practical and private (deep) learning without sampling or shuffling</p></li></ul><h2 id="Scales"><a href="#Scales" class="headerlink" title="Scales"></a>Scales</h2><ul><li><input disabled type="checkbox"> <strong>arXiv’18</strong>-Applied federated learning: Improving Google keyboard query suggestions.</li></ul><h2 id="FL定制"><a href="#FL定制" class="headerlink" title="FL定制"></a>FL定制</h2><ul><li><input checked disabled type="checkbox"> <strong>ICLR’21</strong>-HETEROFL:  computation and communication efficient federated learning for heterogeneous clients-(Enmao Diao-Duke, Jie Ding-UMN, Vahid Tarokh-Duke)-<a href="https://github.com/dem123456789/HeteroFL-Computation-and-Communication-Efficient-Federated-Learning-for-Heterogeneous-Clients">Code</a></li><li><input checked disabled type="checkbox"> <strong>MobiCom’20</strong>-Billion-Scale Federated Learning on Mobile Clients: A Submodel Design with Tunable Privacy</li></ul><h2 id="FL系统"><a href="#FL系统" class="headerlink" title="FL系统"></a>FL系统</h2><h4 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h4><ul><li><input disabled type="checkbox"> <strong>NIPS’19</strong>-Leaf: A benchmark for federated settings-()-<a href="https://leaf.cmu.edu/">Data</a></li><li><input disabled type="checkbox"> <strong>TensorFlow Federated (TFF)</strong>- “TensorFlow federated: Machine learning on decentralized data.”-()-[Data](<a href="https://www.tensorflow/">https://www.tensorflow</a> .org/federated)</li><li><input disabled type="checkbox"> <strong>arXiv’20</strong>-FedML: A research library and benchmark for federated machine learning</li><li><input disabled type="checkbox"> <strong>arXiv’21</strong>-Flower: A friendly federated learning framework</li><li><input disabled type="checkbox"> <strong>MLSys’20</strong>-Mlperf training benchmark</li><li><input disabled type="checkbox"> PySyft (pys)</li><li><input checked disabled type="checkbox"> <strong>ICML22’</strong>-FedScale: Benchmarking Model and System Performance of Federated Learning at Scale</li></ul><h4 id="Others-1"><a href="#Others-1" class="headerlink" title="Others"></a>Others</h4><ul><li><input disabled type="checkbox"> <strong>MLSys’20</strong>-Federated optimization in heterogeneous networks-()-<a href>FedProx</a></li><li><input disabled type="checkbox"> <strong>arXiv’20</strong>-Adaptive federated optimization-()-<a href>FedYoGi</a></li><li><input disabled type="checkbox"> <strong>OSDI’21</strong>-Oort: Efficient federated learning via guided participant selection</li></ul><h2 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h2><ul><li><input checked disabled type="checkbox"> <strong>IEEE Signal Processing Magazine’20</strong>-Federated learning: Challenges, methods, and future directions-(Tian Li-CMU, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith)</li><li><input disabled type="checkbox"> <strong>arXiv’21</strong>-Advances and Open Problems in Federated Learning-()</li><li><input disabled type="checkbox"> <strong>ACM Computing Surveys (CSUR)’19</strong>-Demystifying parallel and distributed deep learning: An in-depth concurrency analysis</li></ul><h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h2><ul><li><input disabled type="checkbox"> <strong>arXiv’18</strong>-Federated learning for mobile keyboard prediction</li><li><input disabled type="checkbox"> <strong>arXiv’18</strong>-LoAdaBoost: Lossbased adaboost federated machine learning on medical data</li></ul><h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><h3 id="Novel-models-of-asynchrony"><a href="#Novel-models-of-asynchrony" class="headerlink" title="Novel models of asynchrony"></a>Novel models of asynchrony</h3><p>bulk synchronous approaches and asynchronous approaches, it is worth studying the effects of this more realistic device-centric communication scheme</p><h3 id="Extreme-communication-schemes"><a href="#Extreme-communication-schemes" class="headerlink" title="Extreme communication schemes"></a>Extreme communication schemes</h3><p>optimization methods used for machine learning can tolerate a lack of precision. this error can, in fact, help with generalization. </p><h3 id="Communication-reduction-and-the-Pareto-frontier"><a href="#Communication-reduction-and-the-Pareto-frontier" class="headerlink" title="Communication reduction and the Pareto frontier"></a>Communication reduction and the Pareto frontier</h3><p>how these techniques such as local updating and model compression compose with one another and to systematically analyze the tradeoff between accuracy and communication for each approach. In particular, the most useful techniques will demonstrate improvements at the Pareto frontier.</p><h3 id="Heterogeneity-diagnostics"><a href="#Heterogeneity-diagnostics" class="headerlink" title="Heterogeneity diagnostics"></a>Heterogeneity diagnostics</h3><p>quantify statistical heterogeneity through metrics such as local dissimilarity, however these metrics cannot be easily calculated over the federated network before training occurs</p><h3 id="Granular-privacy-constraints"><a href="#Granular-privacy-constraints" class="headerlink" title="Granular privacy constraints"></a>Granular privacy constraints</h3><h3 id="Beyond-supervised-learning"><a href="#Beyond-supervised-learning" class="headerlink" title="Beyond supervised learning"></a>Beyond supervised learning</h3><h3 id="Productionizing-federated-learning"><a href="#Productionizing-federated-learning" class="headerlink" title="Productionizing federated learning"></a>Productionizing federated learning</h3><ul><li><input disabled type="checkbox"> concept drift(when the underlying data-generation model changes over time)</li><li><input disabled type="checkbox"> diurnal variations(when the devices exhibit different behavior at different times of the day or week)<ul><li><input disabled type="checkbox"> <strong>ICML19’</strong>-Semi-cyclic stochastic gradient descent</li></ul></li><li><input disabled type="checkbox"> cold-start problems(when new devices enter the network)</li></ul><h3 id="Benchmarks"><a href="#Benchmarks" class="headerlink" title="Benchmarks"></a>Benchmarks</h3>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About FL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICLR21-HETEROFL-COMPUTATION AND COMMUNICATION EFFICIENT FEDERATED LEARNING FOR HETEROGENEOUS CLIENTS</title>
      <link href="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/"/>
      <url>/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/</url>
      
        <content type="html"><![CDATA[<h1 id="ICLR21-HETEROFL-COMPUTATION-AND-COMMUNICATION-EFFICIENT-FEDERATED-LEARNING-FOR-HETEROGENEOUS-CLIENTS"><a href="#ICLR21-HETEROFL-COMPUTATION-AND-COMMUNICATION-EFFICIENT-FEDERATED-LEARNING-FOR-HETEROGENEOUS-CLIENTS" class="headerlink" title="ICLR21-HETEROFL-COMPUTATION AND COMMUNICATION EFFICIENT FEDERATED LEARNING FOR HETEROGENEOUS CLIENTS"></a>ICLR21-HETEROFL-COMPUTATION AND COMMUNICATION EFFICIENT FEDERATED LEARNING FOR HETEROGENEOUS CLIENTS</h1><ul><li><p>作者：</p><ul><li><a href="https://diaoenmao.com/%EF%BC%88Enmao">https://diaoenmao.com/（Enmao</a> Diao）（刁恩茂）（Duke University）</li><li><a href="https://jding.org/%EF%BC%88Jie">https://jding.org/（Jie</a> Ding）（University of Minnesota-Twin Cities）</li><li><a href="https://ece.duke.edu/faculty/vahid-tarokh%EF%BC%88Vahid">https://ece.duke.edu/faculty/vahid-tarokh（Vahid</a> Tarokh）（Duke University）</li></ul></li><li><p>中央服务器用的模型和client用的模型这样的一个FL的前提假设会使得FL的应用得到极大的限制，同时会带来client的无谓的计算和通信开销。于是作者提出在clients上部署几种不同复杂度的模型，不同复杂度的模型分别更新server上模型的不同部分，建立的数学公式较为优美。</p></li><li><p>HETEROFL：address <strong>heterogeneous clients</strong> equipped with very different computation and communication capabilities</p></li><li><p><strong>For the first time</strong>, our method <strong>challenges the underlying assumption of existing work that local models have to share the same architecture as the global model</strong></p></li><li><p><strong>several strategies</strong> to <strong>enhance FL training</strong> and conduct extensive empirical evaluations, <strong>including five computation complexity levels of three model architecture on three datasets</strong></p></li></ul><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><ul><li><p>A widely accepted assumption is that local models have to share the same architecture as the global model (Li et al., 2020b).</p></li><li><p>It is crucial to address heterogeneous clients equipped with very different computation and communication capabilities.</p></li><li><p><strong>HeteroFL</strong>: This model heterogeneity differs significantly from the classical distributed machine learning framework where local data are trained with the same model architecture.</p></li><li><p>Contributions:</p><ul><li><p>模型自定义：propose an easy-to-implement framework <strong>HeteroFL</strong> that can train <strong>heterogeneous local models</strong> and aggregate them stably and effectively into a single global inference model. Outperforms <strong>state-of-the-art results</strong> <strong>without</strong> introducing <strong>additional computation overhead</strong>.</p></li><li><p>设备异构：addresses <strong>various heterogeneous settings</strong>. the learning result <strong>stable and effective</strong>, <strong>the communication costs</strong> are small. a<strong>llow local clients to adaptively contribute to the training of global models</strong>，System heterogeneity and communication efficiency can be well addressed.</p></li><li><p>数据异构：several strategies <strong>robust against the balanced non-IID statistical heterogeneity</strong>, <strong>reduce the number of communication rounds</strong>.</p><p>  <strong>”Masking Trick”</strong> for balanced non-IID data partition in n classification problems</p><p>  a modification of Batch Normalization (BN)</p></li></ul></li></ul><h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><ul><li>train massively distributed models at a large scale (Bonawitz et al., 2019)</li><li><strong>FedAvg</strong> by McMahan et al. (2017) is currently t<strong>he most widely adopted FL baseline</strong>, which r<strong>educes communication cost by allowing clients to train multiple iterations locally.</strong></li><li><strong>communication efficiency</strong>:<ul><li>data compression techniques(quantization and sketching), split learning</li></ul></li><li><strong>system heterogeneity</strong><ul><li>asynchronous communication</li><li>active sampling of clients</li></ul></li><li><strong>statistical heterogeneity</strong>(major battleground)<ul><li><strong>adapt the global model to accommodate personalized local models for non-IID data</strong><ul><li>integrating FL with other frameworks such as assisted learning, metalearning, multi-task learning, transfer learning, knowledge distillation, lottery ticket hypothesis, but <strong>often introduce additional computation and communication overhead</strong> that may not be necessary.</li></ul></li></ul></li><li><strong>privacy</strong><ul><li>model gradient updates can reveal sensitive information or even local training data</li></ul></li></ul><h2 id="HETEROGENEOUS-FEDERATED-LEARNING"><a href="#HETEROGENEOUS-FEDERATED-LEARNING" class="headerlink" title="HETEROGENEOUS FEDERATED LEARNING"></a>HETEROGENEOUS FEDERATED LEARNING</h2><h3 id="HETEROGENEOUS-MODELS"><a href="#HETEROGENEOUS-MODELS" class="headerlink" title="HETEROGENEOUS MODELS"></a>HETEROGENEOUS MODELS</h3><ul><li>consider <strong>local models</strong> to <strong>have similar architecture</strong> but can <strong>shrink their complexity within the same model class</strong>.</li><li><strong>new challenges</strong>: the optimal way to select subsets of global model parameters, compatibility of the-state-of-art model architecture, and minimum modification from the existing FL framework</li><li>we can modulate the size of deep neural networks by <strong>varying the width and depth of networks</strong>(Zagoruyko &amp; Komodakis, 2016; Tan &amp; Le, 2019):<ul><li>Because we <strong>aim to reduce the computation complexity of local models</strong>, we choose to <strong>vary the width of hidden channels</strong></li><li><strong>locally distributed data</strong>: ${X_1,…,X_m}$，m clients。</li><li><strong>model parameters</strong>: ${W_1, …, W_m}$, m clients。</li><li><strong>global model</strong>: $W_g$</li><li>each round:<ul><li>$W_g^t=\frac{1}{m}\sum_{i=1}^{m}W_i^t$</li><li>$W_i^{t+1}=W^t_g$</li></ul></li><li>对于全局参数$W_g \in \bold{R}^{d_g \times k_g}$中的某一个隐藏层$W_l$，$d_g和k_g$分别是输入输出的参数，$W_l$的参数的部分：$W_l^p \subset W_l^{p-1} … \subset W_l^{1}$，那么$W_l$这些部分的参数相对$W_l$有一个shrink，即$d_l^p=r^{p-1}d_g$ and $k_l^p=r^{p-1}k_g$ ，于是有$|W_l^p|=r^{2(p-1)}|W_g|$, shinkage ratio: $R=\frac{W_l^p}{W_g}=r^{2(p-1)}$</li><li>下图展示的就是给不同的clent分配不同大小的model的一个示意图：</li><li><img src="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123.png" class="lazyload placeholder" data-srcset="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></li><li>全局聚合：<ul><li><img src="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668237191694-2.png" class="lazyload placeholder" data-srcset="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668237191694-2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></li><li><img src="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668237570920-4-1668237816488-6.png" class="lazyload placeholder" data-srcset="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668237570920-4-1668237816488-6.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></li><li><img src="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668237829864-8.png" class="lazyload placeholder" data-srcset="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668237829864-8.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></li><li>算力或者网络状况不好的机器就跑小模型，好的就跑大模型，公平高效。</li></ul></li></ul></li></ul><h3 id="STATIC-BATCH-NORMALIZATION"><a href="#STATIC-BATCH-NORMALIZATION" class="headerlink" title="STATIC BATCH NORMALIZATION"></a>STATIC BATCH NORMALIZATION</h3><p>classical FedAvg and most recent works <strong>avoid BN</strong>. A major concern of BN is that <strong>it requires running estimates of representations at every hidden layer</strong>（？）. <strong>Uploading these statistics to the server will cause higher communication costs and privacy issues</strong> Andreux et al. (2020) proposes to track running statistics locally。</p><p>batch normalization在non-IID数据上的表现并不好：<a href="https://zhuanlan.zhihu.com/p/374432534%EF%BC%8Chttps://zhuanlan.zhihu.com/p/309381344%EF%BC%8C%E5%90%8C%E6%97%B6%E5%AD%98%E5%9C%A8privacy">https://zhuanlan.zhihu.com/p/374432534，https://zhuanlan.zhihu.com/p/309381344，同时存在privacy</a> concerns，因为计算用到了全局的数据。</p><p>**static Batch Normaliztion (sBN)**：</p><ul><li>During the training phase, <strong>sBN</strong> does not track running estimates and <strong>simply normalize batch data</strong>.</li><li>We do not track the local running statistics as the size of local models may also vary dynamically. (？)</li><li>This method is suitable for HeteroFL as every communication round is independent. （？）</li><li>After the training process finishes, the server sequentially query local clients and cumulatively update global BN statistics. （？）</li><li>empirically found this trick s<strong>ignificantly outperforms other forms of normalization methods</strong> including the InstanceNorm (Ulyanov et al., 2016), GroupNorm (Wu &amp; He, 2018), and LayerNorm (Ba et al., 2016)</li></ul><h3 id="SCALER"><a href="#SCALER" class="headerlink" title="SCALER"></a>SCALER</h3><ul><li>很有意思：</li><li>local model parameters at different computation complexity levels will digress to various scales： 局部模型自己都有一些个性化的特点，直接用全局模型的参数在本地做推导可能就忽略了这些特点：<ul><li><strong>To directly use the full model during the inference phase</strong>, inverted dropout with dropout rate q scales representations with $\frac{1}{1-q}$ during the training phase。drop out通常在激活函数后面，或是在<strong>sBN和激活层</strong>加入<strong>Scalar</strong>层，将represention放大$\frac{1}{r^{p-1}}$，这样的话全局聚合之后，本地可以直接用本地的数据去做inference，做了<strong>消融实验</strong>。</li><li><img src="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668240923021-10.png" class="lazyload placeholder" data-srcset="/2022/11/12/iclr21-heterofl-computation-and-communication-efficient-federated-learning-for-heterogeneous-clients/123-1668240923021-10.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></li></ul></li></ul><h2 id="EXPERIMENTAL-RESULTS"><a href="#EXPERIMENTAL-RESULTS" class="headerlink" title="EXPERIMENTAL RESULTS"></a>EXPERIMENTAL RESULTS</h2><ul><li><p>600 individual models</p></li><li><p>datasets</p><ul><li>MNIST and CIFAR10 image classification tasks</li><li>WikiText2 language modeling task</li></ul></li><li><p>three different models</p><ul><li>CNN for MNIST</li><li>preactivated ResNet (PreResNet18) for CIFAR10</li><li>Transformer for WikiText2</li></ul></li><li><p>replace BN in CNN and PreResNet18 with our proposed sBN and attach the Scaler module after each convolution layer</p></li><li><p>data partition the same as in (McMahan et al., 2017; Liang et al., 2020).</p></li><li><p><strong>100</strong> clients, fraction <strong>C</strong> of active clients per communication round is <strong>0.1</strong> throughout our experiments</p><ul><li>For <strong>IID data partition</strong>, we uniformly assign the same number of data examples for each client</li><li>For <strong>balanced non-IID data partition</strong>, we assume that <strong>the label distribution is skewed</strong>, where clients will only have examples at most from two classes and the number of examples per class is balanced.</li><li>other kinds of non-IID data partition: the unbalanced non-IID data partition where clients may <strong>hold unbalanced labeled dataset and the feature distribution skew</strong> where clients may hold different features.</li><li><strong>masked language modeling task</strong> with a <strong>15% masking rate</strong> and <strong>assign balanced data examples for each client</strong>, each client will roughly have 3000 different words in their local dataset,</li></ul></li><li><p><strong>five different computation complexity levels</strong> {a, b, c, d, e} with the hidden channel shrinkage <strong>ratio r = 0.5</strong>, we found that it is most illustrative to use the discrete complexity levels <strong>0.5, 0.25, 0.125, and 0.0625</strong></p></li><li><p><strong>Each local client</strong> is assigned an <strong>initial computation complexity level</strong></p></li><li><p>To <strong>demonstrate the effect of dynamically varying computation and communication capabilities</strong>, we uniformly sample from various combinations of computation complexity levels</p></li></ul><h3 id="Masked-Cross-Entropy-Loss"><a href="#Masked-Cross-Entropy-Loss" class="headerlink" title="Masked Cross-Entropy Loss"></a>Masked Cross-Entropy Loss</h3><ul><li><strong>instead of</strong> a full Cross-Entropy Loss <strong>for all classes</strong>, we are motivated to <strong>train each local model only with their corresponding classes</strong>, each local model will train a <strong>sub-task</strong> given locally available label information</li><li><strong>Masked Cross-Entropy Loss</strong>: <strong>mask out the output of the model before passing it Cross-Entropy Loss</strong></li><li>We experimented with several different ways of masking, we find <strong>replacing the last layer outputs that are not associated with local labels with zero achieves both stable and comparable local and global results</strong></li><li>When aggregating local model parameters, we do not aggregate the untrained parameters in the last classification layers</li><li>Masked Cross-Entropy Loss <strong>significantly improve local performance and moderately global performance of balanced non-IID data partition task</strong></li></ul><h2 id="CONCLUSIONS-AND-FUTURE-WORK"><a href="#CONCLUSIONS-AND-FUTURE-WORK" class="headerlink" title="CONCLUSIONS AND FUTURE WORK"></a>CONCLUSIONS AND FUTURE WORK</h2>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About FL </tag>
            
            <tag> About Model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MobiCom20-Billion-Scale Federated Learning on Mobile Clients A Submodel Design with Tunable Privacy</title>
      <link href="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/"/>
      <url>/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/</url>
      
        <content type="html"><![CDATA[<h1 id="MobiCom20-Billion-Scale-Federated-Learning-on-Mobile-Clients-A-Submodel-Design-with-Tunable-Privacy"><a href="#MobiCom20-Billion-Scale-Federated-Learning-on-Mobile-Clients-A-Submodel-Design-with-Tunable-Privacy" class="headerlink" title="MobiCom20-Billion-Scale Federated Learning on Mobile Clients A Submodel Design with Tunable Privacy"></a>MobiCom20-Billion-Scale Federated Learning on Mobile Clients A Submodel Design with Tunable Privacy</h1><p>作者：</p><ul><li><a href="https://niuchaoyue.github.io/%EF%BC%88Chaoyue">https://niuchaoyue.github.io/（Chaoyue</a> Niu）（）（Shanghai Jiao Tong University）</li><li><a href="https://www.cs.sjtu.edu.cn/~fwu/%EF%BC%88Fan">https://www.cs.sjtu.edu.cn/~fwu/（Fan</a> Wu）（吴帆）（Shanghai Jiao Tong University）</li><li>etc</li></ul><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112220418688.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112220418688.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221112220418688"></p><ul><li>针对这样的淘宝推荐模型做的一个FL的改编。</li><li>淘宝的商品太多，本地用户想知道自己有关的商品的词嵌入，肯定不能一次性把几十亿的商品id全部放到自己的本地。</li><li>用户直接向server要和自己相关的商品的id会泄露隐私。本篇文章就是在探讨<strong>如何不泄露用户的隐私</strong>。</li></ul><h2 id="Motivitation"><a href="#Motivitation" class="headerlink" title="Motivitation"></a>Motivitation</h2><ul><li>当前的联邦学习存在一些<strong>问题</strong>：要求客户端充分的<strong>利用整个模型</strong>去训练，在<strong>大规模学习任务和资源受限的手机设备中</strong>效率极低。</li><li>深度学习的输入十分稀疏，因此常常用一个<strong>嵌入层</strong>(embedding layer)，去把输入变到低维，使得相似的输入较为接近，且保留输入的信息较多（淘宝的输入保留了$98.22%$的信息，Google的安卓键盘Gboard保留了超过$2/3$）的信息。淘宝有20亿的商品，比Google的10000词多多了，给所有商品ID的词嵌入需要20亿行，134G空间（嵌入向量的维度为18），<strong>每一个client不可能使用完整的模型</strong>，注意到<strong>每一个client子需要输入的很小的特征空间（例如一个用户可能只有300个商品的浏览记录）</strong>，因此可以在client上只要着一点点的特征空间。</li></ul><h3 id="Submodel"><a href="#Submodel" class="headerlink" title="Submodel"></a>Submodel</h3><p>提出<strong>子模型框架</strong>，客户端只从server下载需要的部分，也就是子模型，并且<strong>只上传子模型（$1.99%$）的更新</strong>。</p><p>上传子模型的更新会带来新的问题：客户端真实需要的<strong>子模型暴露了用户的隐私数据</strong>，违背FL初衷。首先，client下载和上传子模型的时候需要制定一个索引集（index set）作为辅助信息，索引集指示的模型的参数部分可能就是这个用户的输入或者一些其它隐含用户信息的词向量。其次，有了这个索引之后后续的更新也会被服务器知道，可以根据这个更新和模型的参数重建出用户的隐私数据。其次，<strong>淘宝每一个用户的子模型也很难和其它用户的对齐</strong>。</p><p>因此设计一个<strong>安全联邦子模型学习策略，附带一个隐私集联合代理作为基石</strong>。(a secure federated submodel learning scheme coupled with a private set union protocol as a cornerstone)。这个策略的属性：<strong>随机响应，安全聚合，布鲁姆过滤器，定制的可信否认</strong>（randomized response, secure aggregation, and Bloom filter, and endows each client with customized plausible deniability (in terms of local differential privacy) against the position of its desired submodel）</p><h2 id="解决子模型暴露用户隐私的问题"><a href="#解决子模型暴露用户隐私的问题" class="headerlink" title="解决子模型暴露用户隐私的问题"></a>解决子模型暴露用户隐私的问题</h2><ol><li><p><strong>客户端如何下载矩阵的一些行而不需要告诉服务器我需要哪一行和哪一个行的索引。</strong></p><ul><li>客户端直接下载服务器完整的模型，本地把自己需要的模型拉出来（❌）。</li><li><strong>不能下载完整的模型</strong>，private information retrieval（PIR，只读模式，获取到的数据的隐藏(concealment of the retrieved elements)）</li></ul></li><li><p><strong>客户端如何修改矩阵的一些行而不让服务器知道哪一行被修改了或者替换了。</strong></p><ul><li>客户端要是直接去修改模型上的行和列，那么服务器肯定知道它改了什么（❌）。</li><li><strong>首先</strong>进行安全聚合，即先把所有的修改相加组成模型，<strong>然后</strong>使用聚合修改，即把所有修改相加组成的模型应用到整个模型上，这样就不知道谁改了什么。可用的加密策略：很多，例如，the protocol specific to the FL setting in [8] and additively homomorphic encryption [9, 43]。这样的话，只要每一个客户端至少修改了一个它对应向量的数值，那么就无法知道谁改了什么东西。有一个极端的策略叫secure federated learning(SFL)，强制每一轮此所有被选择的客户端都必须参与修改无论他们是不是真的想要修改，隐私保护最好，另一个极端的策略是只让真的想要改他们对应行的客户端参与修改，效率最高。<strong>然而</strong>，不同的客户端倾向于修改<strong>高区分度甚至是互斥的行(highly differentiated or even mutually exclusive rows)<strong>，对于多个客户端一起修改一些行的情况，只有一个客户端参与的概率是很高的，这种条件下安全聚合就</strong>失去了他的作用</strong>。</li></ul></li><li><p>secure federated submodel learning (SFSL)。本文提出的模型：</p><p> 首先确定了每一个轮次联合修改的范围，这样可以对其分化的子模型。关键的困难在于，隐藏客户端想要修改的子模型的位置。原本的SFL使用巨大的索引集，相比之下，SFSL确定了需要的对齐范围，即客户端们的真实索引集的集合，private set union（PSU）。</p><p> 每一个被选择的客户端<strong>生成随机索引集</strong>去替换和保护自己真实的索引集，随机索引集是应用两次随机化相应(random response)生成，<strong>随机化响应的参数</strong>设置<strong>由客户端制定</strong>，使用local differential privacy(LDP)去严格量化deniability的强度，服务器可以从聚集后的修改中推断初客户端的真实意图的概率也可以算出来，随机索引的基数(cardinality)决定了客户端的开销，客户端的真实和随机索引集的交叉控制了其本地训练的开销，每个客户端都能够微调隐私的保护程度和效率。</p></li></ol><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="安全需要"><a href="#安全需要" class="headerlink" title="安全需要"></a>安全需要</h3><p>each client should have plausible deniability of whether a certain index is or is not in its real index set.  <strong>the strength of plausible deniability</strong>, we adopt <strong>LDP</strong>（Local DP，本地的差分隐私）。不仅可以保护external attackers，也可以保护不可信的data curator。</p><ol><li><p><strong>LDP的定义</strong>：</p><p> <img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110221433864.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110221433864.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221110221433864"></p></li></ol><p>来自客户端的输入变了，输出不会变化太多。</p><ol start="2"><li>**允许客户端自定义自己的隐私等级。</li></ol><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110233043387.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110233043387.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221110233043387"></p><ol start="3"><li><p><strong>随机Response</strong></p><p> 假设我们想要调研一个敏感问题，如调查已婚人群中的出轨比率，那么让每一个被调研者如实回答问题必然导致个人隐私被侵犯。但是我们想要获取的是统计信息，而非每一个个体的信息，因此可以构建如下随机回答算法：令受访者自己抛一枚均匀硬币，如果正面朝上，那么如实回答问题，如果背面朝上，那么再抛一枚硬币，正面朝上回答是，背面朝上回答否。这样，对于受访者而言，无论他回答的结果如何都不会侵犯隐私，因为对于一个人而言至少有四分之一的概率会回答“有出轨”，因此他的回答并不会透露真实的情况。而对于研究者而言，出轨比例p可以通过简单的计算得到：</p></li></ol><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110233329380.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110233329380.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221110233329380"></p><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110233823708.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221110233823708.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221110233823708"></p><h2 id="DESIGN-OF-SFSL"><a href="#DESIGN-OF-SFSL" class="headerlink" title="DESIGN OF SFSL"></a>DESIGN OF SFSL</h2><h3 id="Design-Rationale"><a href="#Design-Rationale" class="headerlink" title="Design Rationale"></a>Design Rationale</h3><p><strong>key design principles</strong> through how to handle the <strong>two fundamental problems</strong> raised in Section 1.4 and how to resolve <strong>several practical issues</strong></p><h4 id="Solve-two-fundamental-problems"><a href="#Solve-two-fundamental-problems" class="headerlink" title="Solve two fundamental problems"></a>Solve two fundamental problems</h4><p><strong>two fundamental problems</strong> :</p><ul><li>How a client can <strong>download</strong> a row of a matrix, which represents the global/full model and is maintained by an untrusted cloud server, <strong>without revealing which row or the row index to the cloud server</strong>;</li><li>how a client can <strong>modify</strong> a row of the matrix, still <strong>without revealing which row was modified and the altered content</strong>. </li></ul><p>Design:</p><ul><li>During the <strong>download and upload phases</strong>, a client consistently <strong>uses a randomized index set in place of its real index set</strong></li><li>during the <strong>local training phase</strong>, the client <strong>leverages the intersection of its real and randomized index sets</strong>, the client holds <strong>plausible deniability</strong> of some index being in or not in its real index set.</li></ul><p>examine the feasibility of index set randomization in handling two problems:</p><ul><li><strong>For the first problem</strong> in the download phase, if a client intends (resp., does not intend) to download a certain row, and it actually downloads (resp., does not download), it can blame its action to randomization</li><li><strong>Regarding the second problem</strong> in the upload phase, the usage of the randomized index set still empowers a client to deny its real intention of modifying or not modifying some row, even if the cloud server observes its binary action of modifying or not modifying</li></ul><p>for a concrete row, there are two different groups of clients involved in the joint modification:</p><ul><li>(1) One group consists of <strong>those clients who intend to modify the row and contribute nonzero modifications</strong>;</li><li>(2) the other group comprises <strong>those clients who do not intend to modify the row and pretend to modify by submitting zero modifications</strong>. </li><li><strong>With the secure aggregation guarantee</strong>(???)，it is <strong>hard to identify any individual modification</strong> and further to infer whether some client originally intends to perform a modification or not</li><li>The <strong>hardness</strong> is controlled by <strong>the sizes of two groups</strong>：<strong>the probabilities of an index in and not in the real index set</strong>.  <strong>Tunable</strong></li></ul><h4 id="two-practical-issues"><a href="#two-practical-issues" class="headerlink" title="two practical issues"></a>two practical issues</h4><ul><li>The first issue regards <strong>whether it is practical and necessary for the cloud server to ask “Do you have a certain index?” for each index in the full index set</strong>? <strong>Impractical</strong>  and <strong>Unnecessary</strong> . <ul><li>We turn to <strong>narrowing down the scope to the union of 𝑛 chosen clients’ real index sets</strong>, which is normally far smaller than the full index set (i.e., <strong>the union of the whole clients’ real index sets</strong>), it is <strong>unnecessary to cover any index outside the union of 𝑛 chosen clients’ real index sets</strong>. (这样会不会导致一些商品永远无法被用户所感知到？)</li><li>how multiple clients can obtain the union of their real index sets under the mediation of an untrusted cloud server without revealing any client’s real index set(Prosecution Services Unit, <strong>PSU</strong>):<ul><li><strong>a novel design of PSU</strong> based on <strong>Bloom filter</strong> and <strong>secure aggregation</strong></li></ul></li></ul></li><li>The second issue regards <strong>the longitudinal privacy</strong> when a client is chosen to participate in multiple rounds of FSL<ul><li>we need to extend the initial version to <strong>allow repeated responses from the same client to those already answered indices</strong>. (key principles from randomized aggregatable privacypreserving ordinal response (RAPPOR) [19, 21]): the noisy answers generated by the inner (permanent) randomized response will <strong>be memoized and permanently replace the real answers</strong> in the outer (instantaneous) randomized response</li></ul></li></ul><h3 id="Design-Details"><a href="#Design-Details" class="headerlink" title="Design Details"></a>Design Details</h3><h4 id="Secure-Federated-Submodel-Learning-SFSL"><a href="#Secure-Federated-Submodel-Learning-SFSL" class="headerlink" title="Secure Federated Submodel Learning (SFSL)"></a>Secure Federated Submodel Learning (SFSL)</h4><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112212046250.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112212046250.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221112212046250"></p><ul><li>At the initial stage, the cloud server randomly initializes the global model (Line 1). In each communication round, the cloud server selects 𝑛 clients to participate (Lines 2 and 3) and also maintains an up-to-date set of the chosen clients who are alive throughout the whole round, denoted by $\hat{C}$. A chosen client determines its real index set based on its local data, which specifies the “position” of its truly required submodel (Line 10)。</li><li>Then, the cloud server launches PSU to obtain the union of the chosen clients’ real index sets while keeping each individual client’s real index set in secret (Lines 4 and 11)。</li><li>The union is delivered to live clients for them to generate randomized index sets with customized LDP guarantees against the cloud server (Line 12）</li><li>Each live client will use its randomized index set, rather than its real index set, to download the submodel and to securely upload the submodel update (Lines 13 and 19)</li><li>Upon receiving the randomized index set from a client, the cloud server stores it for later usage and returns the corresponding submodel and training hyperparameters to the client (Line 6)</li><li>the client extracts a succinct submodel and prepares involved data as the succinct training set (Line 14).  For example, if a Taobao user’s real index set is {1, 2, 4}, and his/her randomized index set is {2, 4, 6, 9}, he/she receives a submodel with the row indices {2, 4, 6, 9} from the cloud server, but just needs to train the succinct submodel with the row indices {2, 4} over his/her local data <strong>involving the goods IDs {2, 4}</strong>,  <strong>(why???)</strong></li><li>After training under the preset hyperparameters, the client obtains the update of the succinct submodel (Line 15)</li><li>it prepares the submodel update to be uploaded with the randomized index set by adding the update of the succinct submodel to the rows with the succinct indices and padding zero vectors to the other rows (Line 16)</li><li>To help the cloud server average multiple submodel updates according to the size of relevant local training data, <strong>each chosen client also needs to count the number of its training samples involving every index</strong> in the randomized index set (Line 17). the numbers of samples involving the indices outside the succinct index set are all zeros.</li></ul><h4 id="Index-Set-Randomization"><a href="#Index-Set-Randomization" class="headerlink" title="Index Set Randomization"></a>Index Set Randomization</h4><p>how a client can generate a randomized index set in each participating round</p><ul><li>basic design</li></ul><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112214156196.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112214156196.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221112214156196"></p><ul><li>let client 𝑖 maintain two index sets with “Yes” and “No” answers in the permanent randomized response</li></ul><ul><li>Client 𝑖’s Index Set Randomization</li></ul><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112214520078.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112214520078.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221112214520078"></p><ul><li>主要解决 随机生成的index跟随轮次变化的问题，希望跟随轮次的变化，用户要的index也不要被猜出来。细节见原文。</li></ul><h4 id="Private-Set-Union-PSU"><a href="#Private-Set-Union-PSU" class="headerlink" title="Private Set Union (PSU)"></a>Private Set Union (PSU)</h4><p><img src="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112214740791.png" class="lazyload placeholder" data-srcset="/2022/11/12/mobicom20-billion-scale-federated-learning-on-mobile-clients-a-submodel-design-with-tunable-privacy/image-20221112214740791.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221112214740791"></p><h2 id="THEORETICAL-ANALYSIS"><a href="#THEORETICAL-ANALYSIS" class="headerlink" title="THEORETICAL ANALYSIS"></a>THEORETICAL ANALYSIS</h2><h3 id="Security-and-Privacy-Analyses"><a href="#Security-and-Privacy-Analyses" class="headerlink" title="Security and Privacy Analyses"></a>Security and Privacy Analyses</h3><h3 id="Complexity-Analysis-and-Comparison"><a href="#Complexity-Analysis-and-Comparison" class="headerlink" title="Complexity Analysis and Comparison"></a>Complexity Analysis and Comparison</h3><h2 id="EVALUATION"><a href="#EVALUATION" class="headerlink" title="EVALUATION"></a>EVALUATION</h2><ul><li>Dataset</li><li>Model, Hyperparameters, and Metric</li><li>Prototypes and Configurations</li></ul><h3 id="Model-Accuracy-and-Convergency"><a href="#Model-Accuracy-and-Convergency" class="headerlink" title="Model Accuracy and Convergency"></a>Model Accuracy and Convergency</h3><h3 id="Communication-Overhead"><a href="#Communication-Overhead" class="headerlink" title="Communication Overhead"></a>Communication Overhead</h3><h3 id="Computation-Overhead"><a href="#Computation-Overhead" class="headerlink" title="Computation Overhead"></a>Computation Overhead</h3><h3 id="Memory-and-Disk-Loads"><a href="#Memory-and-Disk-Loads" class="headerlink" title="Memory and Disk Loads"></a>Memory and Disk Loads</h3><h3 id="Discussion-on-Billion-Scale-Issues"><a href="#Discussion-on-Billion-Scale-Issues" class="headerlink" title="Discussion on Billion-Scale Issues"></a>Discussion on Billion-Scale Issues</h3><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About FL </tag>
            
            <tag> About Model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OSDI21-Oort Efficient Federated Learning via Guided Participant Selection</title>
      <link href="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/"/>
      <url>/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/</url>
      
        <content type="html"><![CDATA[<ul><li>Oort优化了中央服务器选择client的策略，不再用random选择的策略，而是给每一个client都设置一个名叫utility的东西，utility是根据client的历史上根据对model的更新算出来的.</li><li>优化了statistical model efficiency和system efficiency</li><li>同时做出了一个可以让开发者选择自己想要的数据的系统方便开发者去做测试。</li></ul><p>作者是怎么在那么多上使用ImageNet数据集跑MobileNet模型的？每个clienr是怎么确定自己用什么样的数据的？</p><p><a href="https://zhuanlan.zhihu.com/p/507487766">一种新型的联邦分布式架构（Oort）及未来研究方向 - 知乎 (zhihu.com)</a></p><h1 id="OSDI21-Oort-Efficient-Federated-Learning-via-Guided-Participant-Selection"><a href="#OSDI21-Oort-Efficient-Federated-Learning-via-Guided-Participant-Selection" class="headerlink" title="OSDI21-Oort Efficient Federated Learning via Guided Participant Selection"></a>OSDI21-Oort Efficient Federated Learning via Guided Participant Selection</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul><li><strong>Target</strong>: improve the performance of federated training and testing with guided participant selection<ul><li>prioritizes the use of those clients who have both data that offers the greatest utility in improving model accuracy and the capability to run training quickly</li><li>To enable FL developers to interpret their results in model testing, Oort enforces their requirements on the distribution of participant data while improving the duration of federated testing by cherry-picking clients</li></ul></li><li><strong>Result</strong>: time-to-accuracy performance by 1.2×-14.1× and final model accuracy by 1.3%-9.8%, while efficiently enforcing developer-specified model testing criteria at the scale of millions of clients.</li><li>方法：通过选择一个client的子集（通过client最近的loss去选择，惩罚会导致全局聚合时间增加的client）去优化statistical model efficiency和system efficiency<ul><li>选择client的方法用的是FL已经给你提供的信息，并且限制参与者的数量。（可以通过调参兼顾模型的公平性和保护隐私的要求）。</li><li>开发者可以自定义测试数据集的分布去debug model efficiency。</li><li>PySyft上实现，真实的workloads上测试。</li></ul></li></ul><h2 id="Background-and-Motivation"><a href="#Background-and-Motivation" class="headerlink" title="Background and Motivation"></a>Background and Motivation</h2><h3 id="FL"><a href="#FL" class="headerlink" title="FL"></a>FL</h3><p>联邦学习通常每一轮几百台设备，花好几天训练完成。（为什么不挑选出人数最多的分布去做训练？然后在设备上做finetune）</p><p>开发者测试的时候有挑选出一部分数据集做训练的需求：</p><ul><li>“50k representative samples”</li><li>“x samples of class y”</li><li>“a subset with less than X% data deviation from the global”</li></ul><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><ul><li>数据异构性：展示了一些数据集上不同clients之间数据规模和pairwise data divergence的CDF图。</li><li>设备异构性：用mobilenet在几百个设备上跑，计算了<strong>推导延迟</strong>和<strong>网络的吞吐率</strong>画了两张图。</li><li>Enormous population and pervasive uncertainty</li><li>Privacy concerns</li></ul><h3 id="Limitations-of-Existing-FL-Solutions"><a href="#Limitations-of-Existing-FL-Solutions" class="headerlink" title="Limitations of Existing FL Solutions"></a>Limitations of Existing FL Solutions</h3><ul><li>the potential for curbing these disadvantages by cherry-picking participants before execution has largely been overlooked</li><li>Suboptimality in maximizing efficiency： 用MobileNet和ShuffleNet在1.6 million的OpenImage数据集上做训练，在超过一万四的clients上随机选择100个做训练，用图片在100clients均匀分布训练出的结果为upper bound，发现即使用了YoGi和Prox等优化技术，忽略系统的异构性都会显著增加每一轮此的延迟。</li><li>Inability to enforce data selection criteria：当前的participants选择策略不仅影响执行，也影响最终训练的bias和confidence。使用预训练的shufflenet做训练的时候，和数据的全局分布比起来，差距也很大，尽管当clients数量增加的时候，这种deviation会减少，但是<strong>去量化不同客户端数量下的这种偏差</strong>，仍然十分重要。同时，即使选择了很多的clients，开发者仍然不能指定他们想要的数据集的分布，比如开发者想要一个相对balanced datasets，但是randomchoice可能会导致这样的bias，如图4(b)所示。</li></ul><h2 id="Oort设计"><a href="#Oort设计" class="headerlink" title="Oort设计"></a>Oort设计</h2><p>Oort is a participant selection framework that identifies and cherry-picks valuable participants for FL training and testing</p><ul><li>位于Coordinator里面，和FL execution interact.</li><li>Given developer-specified criteria, it responds with a list of participants, whereas the driver is in charge of initiating and managing execution on the Oort-selected remote participants</li></ul><p><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111134439590.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111134439590.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111134439590"></p><p>Oort interacts with the developer and FL execution frameworks. </p><ul><li><strong>Job submission</strong>: the developer submits and specifies the participant selection criteria to the FL coordinator in the cloud. </li><li><strong>Participant selection</strong>: the coordinator enquires the clients meeting eligibility properties (e.g., battery level), and forwards their characteristics (e.g., liveness) to Oort.</li><li><strong>Given the developer requirements (and execution feedbacks in case of training 2a）.</strong></li><li><strong>Oort selects participants based on the given criteria and notifies the coordinator of this participant selection( 2b )</strong></li><li>Execution: the coordinator distributes relevant profiles (e.g., model) to these participants, and then each participant independently computes results (e.g., model weights in training) on her data</li><li>Aggregation: when participants complete the computation, the coordinator aggregates updates from participants</li></ul><h3 id="Interface"><a href="#Interface" class="headerlink" title="Interface"></a>Interface</h3><p><strong>Training selector</strong>: </p><ul><li>improve the timeto-accuracy performance of federated training</li><li>it captures the utility of clients in training, and efficiently explores and selects high-utility clients at runtime</li></ul><p><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111135103438.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111135103438.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111135103438"></p><ul><li><strong>When the individual client data characteristics (e.g., categorical distribution) are not provided</strong>, the testing selector determines the number of participants needed to cap the data deviation of participants <strong>from the global</strong></li><li>it cherry-picks participants to <strong>serve the exact developer-specified requirements</strong> on data while minimizing the duration of testing</li></ul><h2 id="联邦模型的训练"><a href="#联邦模型的训练" class="headerlink" title="联邦模型的训练"></a>联邦模型的训练</h2><h3 id="the-trade-off-in-selecting-participants-for-FL-training"><a href="#the-trade-off-in-selecting-participants-for-FL-training" class="headerlink" title="the trade-off in selecting participants for FL training"></a>the trade-off in selecting participants for FL training</h3><p>客户端数据和系统performance有coupled的本质，因此要综合考虑。</p><p>又使用了MobileNet在OpenImage的dataset可视化了这两个有效性的分别的影响（Figure 7）.</p><ul><li>优化System Efficiency（“Opt-Sys. Efficiency”）能够减少每个轮次的执行时间（例如选择最快的clients），这可能会导致更多的训练轮次（相比随机选择而言），因为client的数据之前可能已经被其它参与者过去的轮次的数据表示过了（<strong>为什么？</strong>）。</li><li>选择高statistical utility（”Opt-Stat. Efficiency”）的clients可能会导致每一轮的时间更长（如果clients是system的bottleneck的话（<strong>为什么</strong>？））</li><li><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111141201330.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111141201330.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111141201330"></li></ul><h3 id="how-Oort-quantifies-the-client-utility-while-respecting-privacy"><a href="#how-Oort-quantifies-the-client-utility-while-respecting-privacy" class="headerlink" title="how Oort quantifies the client utility while respecting privacy"></a>how Oort quantifies the client utility while respecting privacy</h3><h4 id="Client-Statistical-Utility："><a href="#Client-Statistical-Utility：" class="headerlink" title="Client Statistical Utility："></a>Client Statistical Utility：</h4><p>be able to efficiently capture the client data utility toward improving model performance for various training tasks, and respect privacy</p><p><strong>leverage importance sampling</strong>：就是选择带来梯度更新最大的clients，</p><p><strong>impractical</strong>：</p><ul><li>客户端算这些范数的时候会带来额外的时间开销。</li><li>这个梯度范数随着模型的更新会不断的变化。（为什么这是impractical的理由？）</li></ul><p><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111141548161.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111141548161.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111141548161"></p><p><strong>因此</strong>：做了个近似来减少时间开销，就是用loss而不是用weights（感觉像是编了个故事，先编个比较难的，然后说它不好，然后说我这个好，搞个简单的）。Insight：更大的梯度对应着更大的loss（为什么？）</p><p><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111142603020.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111142603020.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111142603020"></p><p><strong>How Oort respects privacy：</strong></p><ul><li>Training loss measures the prediction confidence of a model without revealing the raw data and is often collected in real FL deployments。（人家都收集了这个，我这个没有额外的收集数据）。</li><li>三种考虑隐私的方式（其实就是对上面这个公式的解释，没有额外的多做多少工作）：<ul><li>只依靠loss选择client，loss是本地计算的，不会揭示客户端上样本的数据分布。</li><li>和LDP一样，即使的loss引起了隐私问题，也可以用差分隐私技术去解决这样的问题。</li><li>Oort可以灵活的更换其它的选择client的客户端的策略。</li></ul></li><li>在technical report上有进一步的各种策略的理论分析（比如使用batch数据的梯度的norm），并且用实验展示了使用数据有噪音情况下的较好的性能（为了证明确实可以用差分隐私这样的技术去解决这个问题）。</li></ul><h4 id="Trading-off-Statistical-and-System-Efficiency"><a href="#Trading-off-Statistical-and-System-Efficiency" class="headerlink" title="Trading off Statistical and System Efficiency"></a>Trading off Statistical and System Efficiency</h4><p>Simply selecting clients with high statistical utility can hamper the system efficiency。（因为statistical utility的增加会导致训练时间的增长，这可能会影响system efficiency，好的system efficiency应该是训练每一轮此的时间相对来说比较快的），采取了图中所示的计算方式。</p><ul><li>t是每一个客户端训练的时间。</li><li>惩罚了那些会成为系统overhead的客户端。</li></ul><p><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111150040681.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111150040681.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111150040681"></p><ul><li><p><strong>Navigating the trade-off</strong>：</p><p>  <img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111153210944.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111153210944.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111153210944"></p><p>  随着round的进行，模型的loss会逐渐下降，在<strong>模型的训练的后期，应该减小对能够取得高statistical utility的clients的选择</strong>：</p><p>  <img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111153506139-1668152108109-1.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111153506139-1668152108109-1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111153506139"></p></li></ul><h4 id="how-it-selects-high-utility-clients-at-scale-despite-staleness-in-client-utility-as-training-evolves"><a href="#how-it-selects-high-utility-clients-at-scale-despite-staleness-in-client-utility-as-training-evolves" class="headerlink" title="how it selects high-utility clients at scale despite staleness in client utility as training evolves"></a>how it selects high-utility clients at scale despite staleness in client utility as training evolves</h4><p>还有一些其它的考虑：</p><ul><li><strong>Scalability</strong>: a client’s utility can only be determined after it has participated in training; <strong>how to choose from clients at scale without having to try all clients once</strong>? （为了提高选择器的效率）</li><li><strong>Staleness</strong>: since not every client participates in every round, <strong>how to account for the change in a client’s utility since its last participation</strong>?（客户端并不是每一轮都参加的，如何处理这样的问题）。</li><li><strong>Robustness</strong>: how to <strong>be robust to outliers in the presence of corrupted clients</strong> (e.g., with noisy data)? （如何对有outliers的数据鲁棒）</li></ul><p>做了一些实验上的探索：</p><p><strong>Online exploration-exploitation of high-utility clients</strong></p><ul><li>将选择客户端抽象为多臂老虎机问题，clients比作“arm”，utility比作“reward”，多臂老虎机和强化学习的方法比起来，scalable and flexible（即使解空间例如客户端的数量跟随时间变化很大）（这里其实就是解释为什么要用多臂老虎机，这样好）。<strong>多臂老虎机既可以根据之前的概率做出选择，也可以探索未被选择的客户端：</strong><ul><li>每一个选择轮次开始的时候,Oort都接受上一个训练轮次的反馈，会更新每一个客户端的statistical utility和system performance。</li><li>对于已经explored的客户端来说，Oort计算客户端的utility并依据high-utility减小选择的范围。</li><li>然后采样$\epsilon \in [0,1]$比率的participants（那些之前没有被selected的）。 </li></ul></li></ul><p><strong>Exploitation under staleness in client utility</strong></p><p>受到多臂老虎机置信区间的影响，搞了个incentive term，慢慢的增加client的utility（如果一个client已经被忽略了很长的时间），这样的话当一个client被忽略很久了，他的被选的概率会慢慢的增加。</p><p>不直接的选择top-k的utility，搞了个confidence interval c on the cut-off utility（默认$95%$），就是选择utility大于$c%$的top $(1-\epsilon) \times K$的，这样的话可以去除clients utility不确定性的干扰。</p><p><strong>Robust exploitation under outliers</strong></p><p>只根据utility选be vulnerable to outliers in unfavorable settings</p><ul><li><p>因此Oort会在一些客户端已经被用过一些轮次之后把其移除。</p></li><li><p>限制client utility的上限值。</p></li></ul><p><strong>Accommodation to diverse selection criteria</strong></p><p>可以自定义utility的计算方法。</p><h2 id="联邦学习的模型测试（没大看懂）"><a href="#联邦学习的模型测试（没大看懂）" class="headerlink" title="联邦学习的模型测试（没大看懂）"></a>联邦学习的模型测试（没大看懂）</h2><h3 id="开发者未自定义数据的分布时默认给出的数据具有代表性"><a href="#开发者未自定义数据的分布时默认给出的数据具有代表性" class="headerlink" title="开发者未自定义数据的分布时默认给出的数据具有代表性"></a>开发者未自定义数据的分布时默认给出的数据具有代表性</h3><p>enable guided participant selection by determining the number of participants needed to guarantee this deviation target.</p><p><strong>好像只是对数据的样本数进行了一个抽取数据的分布的限制，使抽取的数据更加具有代表性。</strong></p><h4 id="Preserving-Data-Representativeness"><a href="#Preserving-Data-Representativeness" class="headerlink" title="Preserving Data Representativeness"></a>Preserving Data Representativeness</h4><p>使用L1 distance去度量所有参与者与全局数据分布的偏差，对于类别X, L1-distance计算如下：</p><p>$\left| \overline{X} - E[\overline{X}] \right|$，表示所有参与者的样本均值和所有clients之间样本均值的关系。</p><p>由于一个客户端的样本的数量不会影响其它客户端的样本的数量，所以每一个客户端的样本的个数可以看作总体X的采样，给定置信度和置信度，我们的<strong>目标</strong>就是求出需要的参与者的数量，这样的话要选出来的代表性的样本的分布被bounded，也就是：</p><p>$Pr[\overline{X}-E[\overline{X}]]&gt;\delta$，这就变成了一个随机数采样的问题，运用了<strong>Hoeffding bound</strong>去度量不同参与者采样得到的数据偏移。（技术报告中有理论的额证明和结果）。</p><h4 id="Estimating-the-number-of-participants-to-cap-deviation"><a href="#Estimating-the-number-of-participants-to-cap-deviation" class="headerlink" title="Estimating the number of participants to cap deviation"></a>Estimating the number of participants to cap deviation</h4><p>即使个体的数据特征不可得，开发者也可以去指定tolerance $\epsilon$，Oort会输出满足这样的tolerance需要的参与者数目。</p><p>模型要求开发者输入每一个client的最大和最小样本数，客户端的总数（为什么要客户端的总数？）。开发者也可以设一个模糊的限制（例如依据设备模型的容量来设置）</p><p>开发者可以将自己的模型先部署到已经选择的参与者上面，再收集了这些参与者的结果之后，再去确认一下计算数据的代表性。</p><h3 id="开发者自定义自己的数据分布"><a href="#开发者自定义自己的数据分布" class="headerlink" title="开发者自定义自己的数据分布"></a>开发者自定义自己的数据分布</h3><p>对于每一个client，根据每一个client可以提供的开发人员需要的样本的数目，每一个client的算力，每一个client上传输的数据大小，每一个client的带宽，可以计算出所有participant上最多的花费时间，我们的目标是优化这个最大时间。</p><p><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111222910741.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111222910741.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111222910741"></p><p>这样的mixed-integer linear programming (MILP) model解出来的结果很好，但是<strong>时间复杂度较高</strong>，时间复杂度很高（没说多少）。</p><ul><li><p>贪心的启发式算法解决时间复杂度高的问题：</p><p>  <img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111223455902.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111223455902.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111223455902"></p></li></ul><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>Oort，2617行代码，和FL engine例如（PySyft和TensorFlow集成）。</p><ul><li>低消耗</li><li>定期备份。</li><li>故障恢复。</li><li>Gurobi solver去解决MILP问题。</li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>68个英伟达 Tesla P100的GPUs上每一轮模拟了1300个参与者，在。训练和测试阶段模拟真实的异构client系统的性能和数据，使用了一个开源的FL benchmark：</p><ul><li>不同的设备</li><li>不同的模型</li><li>不同的网络吞吐量和连接性</li></ul><p>手动的让不同client上的数据产生数据异构性。</p><p>coordinator和clients之间的交流架构是参数服务器架构。（PySyft和真实的FL部署都是这么干的）。</p><p>为了减小staggers的影响，使用了真实FL部署中使用的机制。</p><p><strong>数据集和模型</strong>：</p><p><img src="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111224714887.png" class="lazyload placeholder" data-srcset="/2022/11/12/osdi21-oort-efficient-federated-learning-via-guided-participant-selection/image-20221111224714887.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221111224714887"></p><p><strong>模型设置的一些参数</strong></p><h3 id="FL-Training-Evaluation"><a href="#FL-Training-Evaluation" class="headerlink" title="FL Training Evaluation"></a>FL Training Evaluation</h3><h4 id="End-to-End-Performance"><a href="#End-to-End-Performance" class="headerlink" title="End-to-End Performance"></a>End-to-End Performance</h4><ul><li>Oort improves time-to-accuracy performance</li><li>Oort improves final model accuracy</li></ul><h4 id="Performance-Breakdown"><a href="#Performance-Breakdown" class="headerlink" title="Performance Breakdown"></a>Performance Breakdown</h4><ul><li>Breakdown of time-to-accuracy efficiency</li><li>Oort achieves close to upper-bound statistical performance</li></ul><h4 id="Sensitivity-Analysis"><a href="#Sensitivity-Analysis" class="headerlink" title="Sensitivity Analysis"></a>Sensitivity Analysis</h4><ul><li>Impact of number of participants K</li><li>Impact of penalty factor α on stragglers</li><li>Impact of outliers</li><li>Impact of noisy utility</li><li>Oort can respect developer-preferred fairness</li></ul>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About FL </tag>
            
            <tag> About Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICML22-FedScale-Benchmarking Model and System Performance of Federated Learning at Scale&#39;</title>
      <link href="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/"/>
      <url>/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/</url>
      
        <content type="html"><![CDATA[<h1 id="ICML22-FedScale-Benchmarking-Model-and-System-Performance-of-Federated-Learning-at-Scale"><a href="#ICML22-FedScale-Benchmarking-Model-and-System-Performance-of-Federated-Learning-at-Scale" class="headerlink" title="ICML22-FedScale-Benchmarking Model and System Performance of Federated Learning at Scale"></a>ICML22-FedScale-Benchmarking Model and System Performance of Federated Learning at Scale</h1><ul><li>不和大家卷算法，去卷系统去。</li><li>做了一个可以模拟FL任务的系统。</li><li>使用真实的数据集来做测评。</li></ul><h2 id="a-federated-learning-FL-benchmarking-suite"><a href="#a-federated-learning-FL-benchmarking-suite" class="headerlink" title="a federated learning (FL) benchmarking suite"></a>a federated learning (FL) benchmarking suite</h2><ol><li><strong>realistic datasets</strong>（20）（ranging from image classification and object detection to language modeling and speech recognition）。Each dataset comes with a unified evaluation protocol <strong>using real-world data splits and evaluation metrics</strong>。</li><li><strong>a scalable and extensible runtime</strong>。API to implement FL algorithms，deploy them at scale across diverse hardware and software backends, and evaluate them at scale。<ol><li>mobile backend：enable on-device FL evaluation</li><li>a cluster backend： benchmark various practical FL metrics</li></ol></li><li><strong>systematic experiments</strong>（some implications）：highlight the pressing need for co-optimizing system and statistical efficiency, especially in tackling system stragglers, accuracy bias, and device energy trade-offs</li></ol><h2 id="Existing-FL-benchmarks-can-be-misleading"><a href="#Existing-FL-benchmarks-can-be-misleading" class="headerlink" title="Existing FL benchmarks can be misleading"></a>Existing FL benchmarks can be misleading</h2><ol><li>A lot of problems</li></ol><p><img src="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123.png" class="lazyload placeholder" data-srcset="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ol start="2"><li>Figure 2: <ol><li>statistical performance becomes worse when encountering realistic client behavior.</li><li>FL training with hundreds of participants each round performs better than that with tens of participants</li></ol></li></ol><h2 id="Realistic-FL-Workloads"><a href="#Realistic-FL-Workloads" class="headerlink" title="Realistic FL Workloads"></a>Realistic FL Workloads</h2><p><img src="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667052732044-2.png" class="lazyload placeholder" data-srcset="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667052732044-2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h3 id="Realistic-data-and-partitions"><a href="#Realistic-data-and-partitions" class="headerlink" title="Realistic data and partitions"></a>Realistic data and partitions</h3><p><strong>how to generate data?</strong> Following the practical FL deployments (Yang et al., 2018), we assign the clients of each dataset into the training, validation and testing groups. <strong>A high statistical deviation</strong> (e.g., wide distribution of the density) across clients <strong>not only in the quantity of samples</strong> (Figure 3(a)) <strong>but also in the data distribution</strong> (Figure 3(b)).</p><p><strong>hundreds to millions of clients</strong></p><h3 id="Client-device-system-speed-is-heterogeneous"><a href="#Client-device-system-speed-is-heterogeneous" class="headerlink" title="Client device system speed is heterogeneous"></a>Client device system speed is heterogeneous</h3><ol><li>Client device system speed is heterogeneous<ol><li>system trace of different clients: <strong>AI Benchmark (Ignatov et al.)</strong> and <strong>MobiPerf Measurements (mob)</strong> on mobiles.</li><li><strong>AI Benchmark</strong> provides the <strong>training and inference speed of diverse models</strong> (e.g., MobileNet) across a wide range of device models (e.g., Huawei P40 and Samsung Galaxy S20)</li><li><strong>MobiPerf</strong> has collected the available <strong>cloud-to-edge network throughput</strong> of over <strong>100k world-wide mobile clients</strong></li></ol></li><li>Client device availability is dynamic: <strong>a large-scale user behavior dataset</strong>: 136k users (Yang et al., 2021). It includes 180 million trace items of client devices (e.g., battery charge or screen lock) over a week.</li></ol><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p><strong>customize their dataset:</strong> standardized APIs, a Python package, for the user to easily leverage these datasets</p><h3 id="Mobile-Backend"><a href="#Mobile-Backend" class="headerlink" title="Mobile Backend"></a>Mobile Backend</h3><p>enable ondevice FL evaluation</p><p>FedScale mobile backend (Singapuram et al., 2022) is built atop the Termux app (ter),</p><h3 id="Cluster-Backend"><a href="#Cluster-Backend" class="headerlink" title="Cluster Backend"></a>Cluster Backend</h3><h4 id="deployment-mode"><a href="#deployment-mode" class="headerlink" title="deployment mode:"></a>deployment mode:</h4><p><strong>acts as the cloud aggregator</strong> and orchestrates FL executions across real devices</p><h4 id="simulation-mode"><a href="#simulation-mode" class="headerlink" title="simulation mode"></a>simulation mode</h4><p>providing various <strong>practical FL metrics</strong> by emulating realistic FL behaviors, such as <strong>computation/communication cost, latency and wall clock time</strong>. the first platform that enables FL benchmarking with practical FL runtime on GPUs/CPUs</p><ol><li><p><strong>Aggregator Simulator</strong>: </p><p>Once receiving new events, the event monitor activates the <strong>handler</strong> (e.g., aggregation handler to perform model aggregation), or the <strong>gRPC</strong> communicator to send/receive messages. The communicator <strong>records the size (cost)</strong> of every network traffic, and its <strong>runtime latency in FL wall-clock time ( traffic_size / client_bandwidth )</strong></p></li><li><p><strong>Client Simulator</strong>: </p><p>FedScale data loader loads the federated dataset of that client and feeds this data to the compute engine to run real training/testing. <strong>The computation latency</strong>: #_processed_sample × latency_per_sample. <strong>The communication latency</strong> ( traffic_size client_bandwidth ). The device monitor will terminate the simulation of a client if the current FL runtime exceeds his available slot.</p></li><li><p><strong>Resource Manager</strong>: </p><p>when the number of participants/round exceeds the resource capacity (e.g., simulating thousands of clients on a few GPUs), the resource manager queues the overcommitted tasks of clients and schedules new client simulation from this queue once resource becomes available. This queuing will not affect the simulated FL runtime. </p></li></ol><p><strong>automated FL simulation</strong>:</p><ol><li>Task submission</li><li>FL simulation</li><li>Metrics output</li></ol><p><strong>FedScale Runtime is scalable and efficient</strong></p><h2 id="Other-flexible-APIs"><a href="#Other-flexible-APIs" class="headerlink" title="Other flexible APIs"></a>Other flexible APIs</h2><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>10 NVIDIA Tesla P100 GPUs in our evaluations, collects updates from the first N completed participants out of 1.3N participants to mitigate system stragglers in each round.</p><ol><li><p><strong>the performance of existing benchmarks</strong> and <strong>FedScale</strong> are <strong>quite close</strong> in the same settings if we <strong>turn off the optional system traces</strong> in FedScale. (underlying training and FL protocols in evaluations are the same)</p></li><li><p>Benchmarking FL statistical efficiency. (<strong>IID data vs. Non-IID data</strong>)</p><p><img src="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667055455629-4.png" class="lazyload placeholder" data-srcset="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667055455629-4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p></li><li><p>Benchmarking FL system efficiency</p><p>(1). FedScale Runtime enables fast-forward evaluations of the practical FL wall-clock time with fewer evaluation hours. Taking different number of local steps K in local SGD as an example (McMahan et al., 2017), Figure 12(a) and Table 12(b) illustrate that FedScale can evaluate this impact of K on practical FL runtime in a few hours.</p><p>(2). FedScale Runtime can dictate the FL execution cost by using realistic system traces.</p><p><img src="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667055708884-6.png" class="lazyload placeholder" data-srcset="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667055708884-6.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p></li><li><p>Benchmarking FL privacy and security</p><p><img src="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667055979760-8.png" class="lazyload placeholder" data-srcset="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667055979760-8.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p>privacy: DP-SGD (Geyer et al., 2017;Kairouz et al., 2021a): </p></li></ol><p>​        FL security: backdoor attacks (Sun et al., 2019; Wang et al., 2020), </p><h2 id="Implications"><a href="#Implications" class="headerlink" title="Implications"></a>Implications</h2><ol><li>Heterogeneity-aware co-optimizations of communication and computation</li><li>Co-optimizations of statistical and system efficiency</li><li>FL design-decisions considering mobile environment</li></ol><h1 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h1><p><img src="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667056105725-11.png" class="lazyload placeholder" data-srcset="/2022/10/28/icml22-fedscale-benchmarking-model-and-system-performance-of-federated-learning-at-scale/123-1667056105725-11.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About FL </tag>
            
            <tag> Benchmark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OSDI22-Automatic Reliability Testing for Cluster Management Controllers</title>
      <link href="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/"/>
      <url>/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/</url>
      
        <content type="html"><![CDATA[<h1 id="OSDI22-Automatic-Reliability-Testing-for-Cluster-Management-Controllers"><a href="#OSDI22-Automatic-Reliability-Testing-for-Cluster-Management-Controllers" class="headerlink" title="OSDI22-Automatic Reliability Testing for Cluster Management Controllers"></a>OSDI22-Automatic Reliability Testing for Cluster Management Controllers</h1><p><strong>作者根据insight给的一些可能的错误类型，对k8s的调度器调用API的接口进行了一个封装，通过可能的错误类型生成了一些测试计划，找到了一些bug。</strong></p><p>Borg, Omega and Kubernetes 依赖state-reconciliation principle去变得高弹性和可拓展性，所有的<strong>集群管理</strong>的<strong>逻辑</strong>即<strong>控制器</strong>被嵌入在松散耦合的微服务中（这些<strong>集群管理的逻辑就是微服务</strong>）。每一个控制器独立的观测当前的集群的状态，采取特定的措施使得当前的集群满足特定的状态。复杂的分布式的本质是建立稳定性强的正确的控制器很难，控制器面临着<strong>无数的可靠性问题</strong>，导致<strong>数据损失，安全和资源泄漏</strong>。</p><p><strong>Sieve</strong>，测试集群控制器的工具，通过不断的干扰控制器看到的当前集群的状态，然后去比较集群受到干扰和没受到干扰时候的状态去检测安全和liveness的问题。Sieve的设计基于基本<strong>状态恢复系统的基本机会</strong>，这些系统基于<strong>state-centric interfaces between controllers and cluster state</strong>，Sieve找到了46个严重的安全和liveness的bug，35个确认，22个修复，false-positive比例是$3.5%$</p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>控制器遵循<strong>state-reconciliation principle</strong>，reconciles the current state of the cluster to match a desired state. 集群的状态放在逻辑上中心化的，高可用的数据中心，K8S里面的<strong>pods、nodes、volumns和应用实例都被表示为集群中状态的对象</strong>。</p><p><img src="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/123.png" class="lazyload placeholder" data-srcset="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/123.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p>Kubernetes controllers管理Cassandra的时候，删掉pod和finalizing中间如果受到干扰，vol没删掉，就会导致storage的泄漏。</p><p><strong>优点</strong>：高可用，1) 不需要正式的对控制器和集群管理的配置说明文件 2) 不需要假设代码可能在哪里出现bug 3) 高度专业化的测试输入。<strong>只需要创建控制器镜像和基本测试工作流的表示，自动化测试</strong>，即只需要提供manifest说明如何在测试下创建和部署控制器，以及一系列的测试工作流（成熟的控制器一般都有）。</p><p><strong>insight</strong>：认为state-centric interfaces非常适合去观察和干扰控制器的view。<strong>控制器的动作是当前它看到的集群状态的严格函数</strong>。</p><p>1） 自动的修改了控制器声称支持的观测到的集群状态。</p><p>2）自动的使用生成的测试计划，标记安全和liveness的问题。（可以这么做是由于state-centric interfaces的一些特点，这样的系统往往<strong>有简单的高度内聚的</strong>state centric的接口，这种接口基本上只做读写和接收状态改变的操作，并且所有的对象共享策略（例如k8s里面就用同样的域去表示metadata））。</p><p><strong>测试方法：</strong>干扰控制器的view，插入1）中间状态 2）已经失效的状态 3）未观测的状态，根据控制器的状态和行为去生成<strong>测试计划</strong>，避免冗余和无效的测试计划。</p><h2 id="Bg"><a href="#Bg" class="headerlink" title="Bg"></a>Bg</h2><p><strong>k8s的架构</strong>：</p><p><img src="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/123-1667563760827-2.png" class="lazyload placeholder" data-srcset="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/123-1667563760827-2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p>k8s的核心由API服务器的集成和高可用、高一致性的数据存储（etcd）组成，etcd里面存储了<strong>对象状态（pods、volumns、nodes、groups of applications）</strong>，所有k8s中的其他组件都和k8s进行交互。控制器调用API Server中的API去获得Object的状态。</p><p>好处：可拓展性强，增加新的应用的时候只需要增加新的控制器和新的State Object。</p><p><strong>k8s的控制器的工作方式</strong>：</p><p><img src="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/123-1667564276682-4.png" class="lazyload placeholder" data-srcset="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/123-1667564276682-4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p>部署ZooKeeper集群的时候，用户<strong>首先创建</strong>一个ZooKeeper的对象，这个<strong>对象</strong>指定了用户想要的集群的状态，例如多少个，版本，存储的大小，然后<strong>ZooKeeper Controller</strong>接受到ZooKeeper对象被创建的消息，就想方设法达到用户制定的状态，首先创建一个StatefulSet的对象（有状态应用的抽象），然后一个a StatefulSet controller随后被告知一个StatefulSet的对象被创建了，然后轮流的创建pod和volumn，之后scheduler，storage controller，worker都被创建去带来实际的container和volumn。如果这个时候用户编辑了ZooKeeper对象时候，每一个控制器就都会微调达到对应的状态。</p><p><strong>这个测试很重要，控制器的可靠性很难保证，当前的测试方法不行</strong>。</p><h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><p><strong>Sieve tests controllers with the following workflow：</strong></p><ul><li>Collecting reference traces：学习控制器在没有错误时候的表现（测试工作流下），记录这个时候的状态转移，从而对控制器和集群状态交互的接口进行检测。</li><li>生成测试计划：根据参考轨迹生成测试计划（描述了具体的干扰），描述了要注入什么错误，什么时候注入错误。</li><li>避免无效的测试计划：删除多余或者无用的测试计划（例如明显不会导致错误的测试计划）。</li><li>执行测试计划：使用test coordinator，执行每一个测试计划，<strong>test coordinator</strong>监控集群测试时候的状态转变，注入错误。</li><li>检查测试结果：generic, effective, differential oracles to automatically check test results</li></ul><h4 id="如何Perturbing控制器的state-view"><a href="#如何Perturbing控制器的state-view" class="headerlink" title="如何Perturbing控制器的state view"></a>如何Perturbing控制器的state view</h4><p>注入特定的错误（crash、delay、connection change）。</p><p><strong>decouple policy from mechanism</strong>：有利于拓展当前的策略，通过编排潜在的干扰机制增加新的策略。<strong>策略</strong>：a view Sieve exposes to the controller at a particular condition. <strong>机制</strong>：说明了如何注入错误去create a view。</p><h4 id="这三种干扰分别是什么？"><a href="#这三种干扰分别是什么？" class="headerlink" title="这三种干扰分别是什么？"></a>这三种干扰分别是什么？</h4><p><strong>Intermediate states</strong>：中间状态指的是控制器还没完成所有状态更新之前中间的一些状态，在controller失败后，k8s就会开一个新的实例，恢复之前的中间状态。</p><p><img src="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/Snipaste_2022-11-04_21-35-34.png" class="lazyload placeholder" data-srcset="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/Snipaste_2022-11-04_21-35-34.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p>例如RabbitMQ控制器，找到了一个bug：</p><p>workload：尝试将存储从10GB-&gt;15GB,1）首先更新VolCur为15GB，然后更新VolReq为15GB（触发k8s）resize大小。在更新VolCur和VolReq的时候Sieve挂了，但是却不能正确恢复，已经被700行go代码修复了。</p><p><strong>Stale states</strong>：</p><p>图2可以看出来，控制器不直接和consist data stores去交互，而是和API server去交互，API server的话里面的状态可能会受到delayed notifications的影响。</p><p>假如有多个API Server都可用的时候，可能有一些API Server的状态比较新，有的状态不是很新，要是控制器刚开始连的是一个比较新的API Server，然后又连接了一个比较旧的Server（由于负载均衡等原因），控制器可能会做重新配置，但是控制器不应该这么做，应该正确识别这些错误。</p><p>Percona’s MongoDB，找到一个新bug：</p><p><img src="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/Snipaste_2022-11-04_21-45-19.png" class="lazyload placeholder" data-srcset="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/Snipaste_2022-11-04_21-45-19.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p>关闭MongoDB集群的时候，controller等着看见MongoDB的state object的删除的时间戳，控制器看到这个变化的时候，就会删除所有的pods和volumes。</p><p>Sieve让这个控制器就错误的删除了一个live的MongoDB的集群。有一个工作流首先关闭了MongoDB的集群然后重新创建了一个同样的集群，等到新的集群创建完成后，Sieve就引入了一个这样的错误，使得controller把这个集群给删了。</p><p><strong>Unobserved states</strong>：现在的controller设计成level-triggered systems(opposed to being edge-triggered)，和别的设计不同的是，别的设计观测所有的集群状态的改变，做这所有的状态的改变，但是level-triggered systems就只根据当前的状态去控制转变集群的状态.</p><p>Instaclustr’s Cassandra controller，找到了一个bug导致资源泄露和服务失败：</p><p><img src="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/Snipaste_2022-11-04_21-56-52.png" class="lazyload placeholder" data-srcset="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/Snipaste_2022-11-04_21-56-52.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p>在scale-down的时候，controller应该得知pods被删除后移除了所有的volumns，而pods的生命周期是由StatefulSet Controller管理的，Sieve就暂停了了发送给Cassandra控制器的消息，因此Cassandra不知道pods被删除了，这导致Cassandra控制器没有删除对应的volumns。</p><h4 id="如何收集Reference-Traces"><a href="#如何收集Reference-Traces" class="headerlink" title="如何收集Reference Traces"></a>如何收集Reference Traces</h4><p>通过封装API Server的函数，封装了10个函数，在这里面注入干扰。</p><p>由此跑一下所有开发者提供的workload，通过学习每一个controller收到的集群状态改变的提醒，和控制器对集群状态的任何读和写的操作，或者是对API Server的client（也就是controller机器自己）维护的local cache去收集两方面的reference traces：</p><ul><li><strong>Controller trace</strong>：一系列使用client的API就可以观测的时间，例如状态改变的notification，reconciliation cycle的entry和exits，client-API的invocation（调用）</li><li><strong>Cluster state trace</strong>：初始化的集群状态和状态改变的序列。</li></ul><h4 id="如何使用Reference-Traces生成测试计划："><a href="#如何使用Reference-Traces生成测试计划：" class="headerlink" title="如何使用Reference Traces生成测试计划："></a>如何使用Reference Traces生成测试计划：</h4><p>每一个测试计划做一种干扰。</p><p><strong>测试计划</strong>：每一个测试计划由self-contained的文件构成，这个文件描述了<strong>测试工作流、一些列的注入的错误、注入错误这一行为的触发条件</strong>。</p><p>目前支持：</p><ul><li>crash/restart a controller</li><li>disconnect/reconnect a controller to an API server</li><li>block/unblock a controller from processing events</li><li>block/unblock an API server from processing events</li></ul><p>根据测试计划就可以复现bug。</p><p><img src="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/image-20221104221955496.png" class="lazyload placeholder" data-srcset="/2022/10/28/osdi22-automatic-reliability-testing-for-cluster-management-controllers/image-20221104221955496.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg" alt="image-20221104221955496"></p><h4 id="测试计划生成"><a href="#测试计划生成" class="headerlink" title="测试计划生成"></a>测试计划生成</h4><p>制定了一系列规则，在这些规则里生成计划，<strong>这个说法很有意思，不说如何制定测试状态，因为大家看到你是怎么制定的就感觉就这，但是避免无用的测试计划这个说法让我感觉很牛</strong>。</p><ul><li><strong>Intermediate-state rule</strong>：集群从一个状态更新到另一个状态要若干步骤，对于若干个步骤$U_{1}, U_{2}…$，做一个步骤就让Controller崩溃一遍，生成一个测试计划。</li><li><strong>Stale-state rule</strong>：不停的让controller travel back in time，然后给他看以前的状态，方法就是不断的做一些可能会带来冲突效果的操作，去观察controller是否正常。具体的做法是，首先观测到更新U的N个结果，然后搜索之后可能的N’个结果，尽量用例如先删了一个object，再创建一个object这样可能会导致冲突的操作。</li><li><strong>Unobserved-state rule</strong>：跳过可能的正常状态的改变，对于状态对(N, N’)，这样生成测试计划1）先不让控制器看到状态N 2）当N’到来的时候让控制器看到N。</li></ul><h4 id="如何避免无用的测试计划"><a href="#如何避免无用的测试计划" class="headerlink" title="如何避免无用的测试计划"></a>如何避免无用的测试计划</h4><p>依据<strong>测试计划生成产生了大量的测试计划</strong>，太多了，光stale-state就在MongoDB Controller上生成了140000+测试计划。</p><p><strong>a guiding principle</strong>：</p><ul><li>prune a test plan if the test plan does not introduce an intermediate-, a stale- or an unobservedstate that can affect the controller’s outputs.</li><li>the introduced state is identical to states introduced by other test plans.</li></ul><p><strong>3.4.1 Pruning by Causality</strong></p><p>根据<strong>因果关系</strong>（更新U是基于状态N做出来的，那么N和U是因果相关的）筛选。因果关系很难做、现在的k8s不好做因果分析。</p><p>所以制定了<strong>两个规则（个人认为：基于局部性原理）</strong>，可能会导致<strong>false positive</strong>的错误：</p><ul><li>Read-before-update rule：the object pertaining to N is read by the controller before it issues U。更新U是在读取N之后作出的。<strong>个人理解：</strong>刚读过状态就去更新，那么更新U大概率和N相关。</li><li>Earliest-reconciliation rule：N and U happen in the same or adjacent reconciliation cycles.  N和U发生在相同或者相近的reconciliation周期中，可以理解。</li></ul><p><strong>例如只保留至少一个U和N因果相关的测试计划</strong>。</p><p><strong>3.4.2 Pruning Unsuccessful Updates</strong></p><p><strong>忽略任何不改变当前集群状态的更新</strong>。</p><p>理由就是：如果一个更新没有改变当前的集群的状态，就不大可能导致新的状态出现。</p><h4 id="Test-Plan-Execution"><a href="#Test-Plan-Execution" class="headerlink" title="Test Plan Execution"></a>Test Plan Execution</h4><p>由Sieve测试协调器执行。</p><h4 id="Differential-Test-Oracles"><a href="#Differential-Test-Oracles" class="headerlink" title="Differential Test Oracles"></a>Differential Test Oracles</h4><p><strong>3.6.1 Checking End States</strong></p><p><strong>3.6.2 Checking State-Update Summaries</strong></p>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About Serverless </tag>
            
            <tag> About Bug Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SysML19-TOWARDS FEDERATED LEARNING AT SCALE: SYSTEM DESIGN</title>
      <link href="/2022/10/28/sysml19-towards-federated-learning-at-scale-system-design/"/>
      <url>/2022/10/28/sysml19-towards-federated-learning-at-scale-system-design/</url>
      
        <content type="html"><![CDATA[<h1 id="SysML19-TOWARDS-FEDERATED-LEARNING-AT-SCALE-SYSTEM-DESIGN"><a href="#SysML19-TOWARDS-FEDERATED-LEARNING-AT-SCALE-SYSTEM-DESIGN" class="headerlink" title="SysML19-TOWARDS FEDERATED LEARNING AT SCALE: SYSTEM DESIGN"></a>SysML19-TOWARDS FEDERATED LEARNING AT SCALE: SYSTEM DESIGN</h1><p>Android’s AIDL IPC mechanism？</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>把代码放数据那，处理的问题：privacy, ownership, the locality of data</p><h2 id="部分相关工作"><a href="#部分相关工作" class="headerlink" title="部分相关工作"></a>部分相关工作</h2><ol><li><p>general description of FL: McMahan &amp; Ramage (2017)</p></li><li><p>theory of FL: Koneˇ cn  ́ y et al. (2016a), McMahan et al. (2017; 2018)</p></li><li><p>Federated Learning infrastructure:</p><ol><li>whether to focus on asynchronous or synchronous training algorithms: asynchronous training: Dean et al. (2012)</li><li>a consistent trend towards synchronous large batch training: (data center)Goyal et al., 2017; Smith et al., 2018</li><li>(Federated Averaging algorithm)McMahan et al. (2017)</li><li>enhancing privacy guarantees: (differential privacy)McMahan et al., 2018, (Secure Aggregation)Bonawitz et al., 2017</li></ol></li><li><p>Our system:</p><ol><li>Federated Averaging</li><li>Secure Aggregation: ensures that on a global level individual updates from phones are uninspectable</li><li>phone keyboard, tens of millions of real-world devices</li><li>issues: <ol><li>device availability that correlates with the local data distribution in complex ways</li><li>unreliable device connectivity and interrupted execution</li><li>orchestration of lock-step execution across devices with varying availability</li><li>limited device storage and compute resources</li></ol></li></ol></li></ol><h2 id="PROTOCOL"><a href="#PROTOCOL" class="headerlink" title="PROTOCOL:"></a>PROTOCOL:</h2><ol><li><p>训练过程：device训练完毕时，服务器向device发送本轮的全局参数和其他必要的状态例如FL Checkpoint，每个参与者在本地根据全局的状态和本地的数据集进行梯度的计算，将更新的数据发送给服务器，服务器再将这些更新全部聚合。</p></li><li><p>选择：设备的选择，满足一定的条件（例如充电和使用wifi），一轮选择小几百的数据量，满足条件后就和服务器建立起一个双向的连接，用于检查设备的liveness并进行multi-step的交流。（选择的数量大概小几百）。未连接的设备服务器告诉他稍后连接。达到足够数量的设备本轮才算是成功。</p></li><li><p>Pace steering: 给device发送重连的时间窗口，FL Populations少的时候，服务器使用无状态的概率算法拒绝一些设备以确保checkin同时到达。多的时候，使用随机的设备check in时间，避免了thundering herd问题，告诉设备按需连接。</p></li><li><p>服务器</p><ol><li>处理10个-上亿个设备的情况，处理10个-几万个参与者的情况，没一轮的更新可能是千K到几十M。</li><li>多个Coordinators：enable global synchronization and advancing rounds in lockstep，每个Coordinator负责一个FL Population，Coordinator用地址和FL Population的名字注册一个共享锁服务，一个FL Population只能有一个owner。接收并处理每个Selector有多少设备参与的信息，生成Aggregator去管理不同FL任务的轮次。</li><li>Selector：和device交流，不断接受Coordinator的信息（FL Population需要多少设备，如何决定要不要一个设备），当Aggregator生成后，将subset的devices发送给Aggregator。</li><li>Master Aggregator：管理每一个FL任务的轮次，</li><li>流水线优化，这样的架构使得上一轮的报告和下一轮的选择可以一起做。</li></ol></li><li><p>设备:</p><ol><li>服务器分反一个a TensorFlow graph and instructions for how to execute it。</li><li>在example store里面选择数据的标准，如何打包data，设备上跑多少个epoch，计算图中节点的标签个数。维护一个example store，实现提供数据的API，不断的移除旧的数据，并按照平台的推荐对数据进行加密。</li><li>设备中的架构（图2），多租户，可以训练多个FL Population。</li><li>保护FL不受到不可信设备的攻击：不能用用户身份授权，所以用了Android’s remote attestation mechanism，并且这样的方式也提供了data poisoning的保护(Bagdasaryan et al., 2018)，</li></ol></li><li><p>通过分析数据去监测Device的健康（将数据上传到云）：</p><p>Device上传：训练被激活时设备的状态，跑了多频繁和多久，用了多少内存，有什么错误，OS等等，不包含用户信息（PII），记录设备的状态序列。服务器端记录：每一个轮次多少设备被接受和拒绝了等等。</p></li></ol><h2 id="SECURE-AGGREGATION（reporting-phrase）"><a href="#SECURE-AGGREGATION（reporting-phrase）" class="headerlink" title="SECURE AGGREGATION（reporting phrase）"></a>SECURE AGGREGATION（reporting phrase）</h2><p>​    每个设备发送的梯度加密，服务器端只有在收集到足够多的数据之后才进行总和的计算。时间复杂度随着用户是O($用户数^2$)，首先所有的Aggregator做安全聚合（固定的数目k），然后Master Aggregator再做一次非安全聚合。</p><h2 id="工具和工作流："><a href="#工具和工作流：" class="headerlink" title="工具和工作流："></a>工具和工作流：</h2><ol><li><p>不能直接推测每一个的训练样本? 做一个工具去查看测试和模拟的数据</p></li><li><p>新修改的模型要编成FL Plan再放到服务器上跑。</p></li><li><p>模型资源的话费和运行时候的兼容性质必须自动的由基础框架验证。</p></li><li><p>如何建立模型？</p><ol><li>定义在手机上跑着的FL任务（训练和评测任务），就是实现对应的函数接口，实现输入向量到loss或者accuracy的映射。部署时候就使用设备上 样本商店 提供的数据。</li><li>除了实现每个设备的FL任务之外，还要给定一个配置文件：一轮多少个设备效果最好，模型的超参（学习率）等等。同时，可以定义多组FLtask，这在比如探索什么样的学习率比较好十分有用。</li><li>使用模型工具可以模拟 FL服务器和一些列设备，使用一些模拟的数据集。 训练出来的结果也可用作预训练的模型。</li></ol></li><li><p>FL Plan生成：</p><ol><li>FL Plan自动由前面的模型和配置生成。这个计划，其实可以由一个python程序表示，python程序会编排一个TF计算图。</li><li>版本、测试和部署管理：<ol><li>模型的更新：<ol><li>必须来自可审计的，同行审议过的代码</li><li>必须在模拟测试集上已经经过测试</li><li>使用的资源限定在一定的范围内</li><li>声称支持的tf上全部经过测试。不同终端上TF版本代码的变换，和数据中心化的训练不同的是，数据中心化的训练可以一直rebuild图，但是终端上的设备的TF runtime版本可能很老。因此由FL infrastructure来对FL Plan进行等价的变换以适应特定的版本，不同的版本经过同样的release test以确保不同的版本的变换是等价的。</li></ol></li><li>数据的写入：每一轮结束之后，模型的聚类的参数就会被写到server的被指定的位置。每个设备的每一次训练由任务名称、论次名称和其他的一些数据标识，对应的一些指标可以由这个系统去分析。</li></ol></li></ol><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2></li><li><p>On-device item ranking</p></li><li><p>Content suggestions for on-device keyboards</p></li><li><p>Next word prediction</p></li></ol><h2 id="OPERATIONAL-PROFILE（经验）"><a href="#OPERATIONAL-PROFILE（经验）" class="headerlink" title="OPERATIONAL PROFILE（经验）"></a>OPERATIONAL PROFILE（经验）</h2><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> About Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Thesis </tag>
            
            <tag> About FL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论部分内容复习</title>
      <link href="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/"/>
      <url>/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="概率论部分内容复习"><a href="#概率论部分内容复习" class="headerlink" title="概率论部分内容复习"></a>概率论部分内容复习</h1><h2 id="卡方分布"><a href="#卡方分布" class="headerlink" title="卡方分布"></a>卡方分布</h2><p>设$X_{1}, X_{2}, …, X_{n}$是来自总体$N(0, 1)$的样本，则称统计量</p><p>$$\chi^2=X_{1}^{2}+X_{2}^{2}+…+X_{n}^{2}$$</p><p>服从自由度为n的$\chi^{2}$分布。记为$\chi^{2}\sim \chi^{2}(n)$.</p><ol><li><p><strong>满足可加性：即从总体中分两次抽取$n1$和$n2$个样本的平方和，和一次抽取$n1+n2$个样本的平方和是相等的。</strong></p><p>$$\chi_{1}^{2}+ \chi_{2}^{2} \sim \chi^{2}(n_{1}+n_{2})$$</p></li></ol><h2 id="t分布"><a href="#t分布" class="headerlink" title="t分布"></a>t分布</h2><p>若$X \sim N(0, 1)$, $Y\sim\chi^{2}(n)$，且X, Y相互独立，则称随机变量:</p><p>$t=\frac{X}{\sqrt{Y/n}}$服从自由度为n的t分布。记为$t \sim t(n)$。</p><p><strong>t分布怎么来的？</strong></p><p><strong>源自对$\frac{\overline{X}-\mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0, 1)$的研究。</strong></p><p>也就是根据中心极限定理，从总体X中抽出n个样本，样本的均值为$\overline{X}$，总体的均值为$\mu$，方差为$\sigma$，样本的方差为$\sigma_{\overline{X}}$：</p><p>$\overline{X}\sim N(\mu, \sigma_{\overline{X}}^{2})$即$\frac{\overline{X}-\mu}{\sigma_{\overline{X}}}\sim N(0, 1)$即$t=\frac{\overline{X}-\mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0, 1)$，为自由度问$n-1$的t分布。</p><h2 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><p>和的分布收敛于正态分布的定理如：</p><p><strong>样本均值$\overline{X}\sim N(\mu,\frac{\sigma^{2}}{n})$。</strong></p><h2 id="大数定律"><a href="#大数定律" class="headerlink" title="大数定律"></a>大数定律</h2><p><strong>样本均值依概率收敛于期望值</strong></p><h2 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h2><ul><li>原假设$H_0$：实验之前已有的假设，AB两次测试的差距为0.</li><li>备择假设$H_{1}$：对立于原假设。</li><li><strong>先对总体的特征作出某种假设，然后通过抽样研究的统计推理，对此假设应该被拒绝还是接受作出判断。</strong></li></ul><h3 id="两类错误"><a href="#两类错误" class="headerlink" title="两类错误"></a>两类错误</h3><ul><li><p>原假设为真，即$\mu=\mu_{0}$，无显著性差异。我们却不接受结果，叫<strong>弃真错误，第一类错误</strong>，犯错概率为$\alpha$。<strong>即实际为真，但是样本却抽取到了让我们判断结果为假的情况。</strong></p></li><li><p><strong>显著性水平（犯错的概率）</strong>越大，那么原假设被拒绝的可能性就越大，犯第一类错误的可能性也就越大。<strong>p值</strong>即为在观测数据下拒绝原假设的最小<strong>显著性水平</strong>。</p></li><li><p>原假设为假，即$\mu\neq\mu_{0}$，有显著性差异。我们却接受结果，叫<strong>取伪错误，第二类错误</strong>，犯错概率为$\beta$。<strong>即实际为假，但是样本却抽取到了让我们判断结果为真的情况。</strong></p></li></ul><p><img src="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123.png" class="lazyload placeholder" data-srcset="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h3 id="如何减少两类错误"><a href="#如何减少两类错误" class="headerlink" title="如何减少两类错误"></a>如何减少两类错误</h3><p><img src="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667132397600-2.png" class="lazyload placeholder" data-srcset="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667132397600-2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h3 id="显著性水平"><a href="#显著性水平" class="headerlink" title="显著性水平"></a>显著性水平</h3><p><img src="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667132490168-4.png" class="lazyload placeholder" data-srcset="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667132490168-4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h3 id="p值计算"><a href="#p值计算" class="headerlink" title="p值计算"></a>p值计算</h3><p><img src="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667133450982-6.png" class="lazyload placeholder" data-srcset="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667133450982-6.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h3 id="置信水平和区间"><a href="#置信水平和区间" class="headerlink" title="置信水平和区间"></a>置信水平和区间</h3><p><img src="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667133632548-8.png" class="lazyload placeholder" data-srcset="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667133632548-8.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p><img src="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667133747607-10.png" class="lazyload placeholder" data-srcset="/2022/10/28/gai-lu-lun-yu-shu-li-tong-ji/123-1667133747607-10.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p><strong>理解：置信区间可以理解成总体均值等量用样本表示时候，往往在什么样的范围内，在这个范围内的概率就是置信水平。</strong></p><ul><li>为什么要置信区间，因为<strong>误差不可避免</strong>，<strong>置信区间即为统计量的误差范围</strong>。比如用$[a,b]$表示样本估计总体均值的误差范围，那么这一结果具有的<strong>可信程度</strong>，就是置信度。</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>t检验和z检验都可以用来判断样本，几次样本之间的<strong>均值</strong>是否显著，卡方检验用于判断样本偏差是否合理，即用来判断检验抽样是否合理。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>2021.01.18: &lt;&lt;概率论与数理统计&gt;&gt;</li><li>2021.08.22: <a href="https://zhuanlan.zhihu.com/p/346602966">https://zhuanlan.zhihu.com/p/346602966</a>, <a href="https://www.zhihu.com/question/24801731">https://www.zhihu.com/question/24801731</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> About Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Reading </tag>
            
            <tag> About Math </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Build a blog like this</title>
      <link href="/2021/10/14/build-a-blog-like-this/"/>
      <url>/2021/10/14/build-a-blog-like-this/</url>
      
        <content type="html"><![CDATA[<h1 id="How-to-build-a-blog-like-this"><a href="#How-to-build-a-blog-like-this" class="headerlink" title="How to build a blog like this?"></a>How to build a blog like this?</h1><ol><li>How to build a blog like this? What you need is this <a href="https://fuhanshi.github.io/2018/10/03/Hexo-Github%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E7%82%AB%E9%85%B7%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">blog</a> .(There may exists some typos, but it’s not a big problem.)</li><li>Then how to replace a theme? What you need is this <a href="https://www.jianshu.com/p/ef7a29e3ee8e">blog</a>.</li><li>Then where to find many many wonderful themes? What you need is this <a href="https://hexo.io/themes/">website</a>.</li><li>About how to config this website? <a href="https://yuang01.github.io/">clicke here</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> About Me </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Blogs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>About Me</title>
      <link href="/2021/08/07/about-me/"/>
      <url>/2021/08/07/about-me/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> About Me </category>
          
      </categories>
      
      
        <tags>
            
            <tag> About Me </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
